{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ ‚Ññ 9\n",
    "\n",
    "–ò—Å–ø–æ–ª—å–∑—É—è –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ https://github.com/Phylliida/Dialogue-Datasets\n",
    "–ò—Å–ø–æ–ª—å–∑—É—è –º–∞—Ç–µ—Ä–∏–∞–ª—ã –ª–µ–∫—Ü–∏–∏ (–Ω–æ—É—Ç–±—É–∫ ) –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å seq2seq —Å –º–µ—Ö–∞–Ω–∏–∑–º–æ–º –≤–Ω–∏–º–∞–Ω–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã.\n",
    "–í–∑—è—Ç—å 1000 —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T16:41:36.157114Z",
     "start_time": "2019-12-01T16:41:36.153943Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ZdZvVz27mE7c"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import zipfile\n",
    "import collections\n",
    "from torch import nn\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiD3rif6kVxM"
   },
   "source": [
    "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –¥–∞—Ç–∞—Å–µ—Ç —è–Ω–¥–µ–∫—Å —Ç–æ–ª–æ–∫–∏ https://toloka.yandex.ru/datasets/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2o3sL0FZwjTr",
    "outputId": "42ef9f58-ea15-4731-cd3f-e3878ab266b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rZAL8WWIkV15"
   },
   "outputs": [],
   "source": [
    "#data = pd.read_csv('./drive/My Drive/dialogues.tsv', sep='\\t')\n",
    "data = pd.read_csv('dialogues.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8DZtxoc7yM6G"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "qyD9mbL-xojX",
    "outputId": "c99cb4c7-b2e5-4329-eacd-1a02dc85d988",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', ' –ü—Ä–∏–≤–µ—Ç) —Ä–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ   ', ' –ü—Ä–∏–≤–µ—Ç) –ø–æ–¥ –≤–∫—É—Å–Ω—ã–π –∫–æ—Ñ–µ–µ–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–æ–±–æ–ª—Ç–∞—Ç—å –ø–æ—è–≤–∏–ª–æ—Å—å )   ', ' –ß—Ç–æ —á–∏—Ç–∞–µ—à—å? –ú–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –∫–ª–∞—Å—Å–∏–∫–∞   ', ' –Ø —Ç–æ–∂–µ –ª—é–±–ª—é –ø–æ–æ–±—â–∞—Ç—å—Å—è   ', ' –õ—é–±–ª—é –∂–∏–≤–æ—Ç–Ω—ã—Ö, –ø—Ä–æ—Å—Ç–æ –æ–±–æ–∂–∞—é, –∫–∞–∫ –∏ —Å–≤–æ—é —Ä–∞–±–æ—Ç—É)   ', ' –Ø —Ñ–∞–Ω—Ç–∞—Å—Ç–∏–∫—É –ª—é–±–ª—é   ', ' –ê —è –≤—ã—Ä–∞—â–∏–≤–∞—é —Ñ–∏–∞–ª–∫–∏   ', ' –ò –≤–µ–¥—É –∑–¥–æ—Ä–æ–≤—ã–π –∏ –∞–∫—Ç–∏–≤–Ω—ã–π –æ–±—Ä–∞–∑ –∂–∏–∑–Ω–∏!   ', ' –£—Ö —Ç—ã, –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ.   ', ' –¢—ã —Å–ª—É—á–∞–π–Ω–æ –Ω–µ –ø—Ä–∏–Ω—Ü –Ω–∞ –±–µ–ª–æ–º –∫–æ–Ω–µ? –Ø –µ–≥–æ –æ—á–µ–Ω—å –∂–¥—É ..   ', ' –ê —É –º–µ–Ω—è –∏–∑ —Ö–æ–±–±–∏ –∫–∞–∂–¥—É—é –Ω–µ–¥–µ–ª—é —Ç—É—Å–∏—Ç—å —Å –º–æ–∏–º –ª—É—á—à–∏–º –¥—Ä—É–≥–æ–º)  ']\n",
      "[' ', ' –ü—Ä–∏–≤–µ—Ç!   ', ' –ü—Ä–∏–≤–µ—Ç,–ö–∞–∫ –∂–∏–∑–Ω—å?   ', ' –û—Ç–ª–∏—á–Ω–æ) –°–æ–ª–Ω—ã—à–∫–æ —Å–≤–µ—Ç–∏—Ç, –ø—Ç–∏—á–∫–∏ –ø–æ—é—Ç!   ', ' –Ø –≤–æ—Ç —Å–µ–≥–æ–¥–Ω—è –ø–æ–Ω—è–ª, —á—Ç–æ –º–µ–Ω—è —Ç—É–ø–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç, –≤—Å–µ–º –Ω—É–∂–Ω—ã –æ—Ç –º–µ–Ω—è –ª–∏—à—å –¥–µ–Ω—å–≥–∏, –Ω–µ–Ω–∞–≤–∏–∂—É –ª—é–¥–µ–π   ', ' –ß–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è –ø–æ –∂–∏–∑–Ω–∏, —è –≤–æ—Ç –±–∏–∑–Ω–µ—Å–º–µ–Ω.   ', ' –ê —è –≤–æ—Ç —É—á—É –¥–µ—Ç–µ–π, —Ä–∞–±–æ—Ç–∞—é —Å –Ω–∞—á–∞–ª—å–Ω—ã–º–∏ –∫–ª–∞—Å—Å–∞–º–∏   ', ' –ù–µ –≤—Å–µ –ª—é–¥–∏ —Ç–∞–∫–∏–µ, –∫–∞–∫ —Ç—ã –≥–æ–≤–æ—Ä–∏—à—å   ', ' –ü–æ–º–∏–º–æ —Ä–∞–±–æ—Ç—ã —á–µ–º –µ—â–µ —Ç—ã –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è?   ', ' –ö —Å–≤–∞–¥—å–±–µ –≥–æ—Ç–æ–≤–ª—é—Å—å   ', ' –ê —Ç—ã?   ', ' –í–æ—Ç –≤–∏–¥–∏—à—å) –∑–Ω–∞—á–∏—Ç, –Ω–∞—à–µ–ª —Ç–∞–∫—É—é –∂–µ–Ω—â–∏–Ω—É, –∫–æ—Ç–æ—Ä–æ–π –Ω–µ –Ω—É–∂–Ω—ã –æ—Ç —Ç–µ–±—è –¥–µ–Ω—å–≥–∏   ', ' –î–∞ —è –Ω–∞–¥–µ—é—Å—å –Ω–∞ —ç—Ç–æ,–ª—é–±–ª—é –µ–µ  ']\n",
      "[' ', ' –ü—Ä–∏–≤–µ—Ç   ', ' –ö–∞–∫ –¥–µ–ª–∞ ?   ', ' –î–æ–±—Ä—ã–π –¥–µ–Ω—å!   ', ' –•–æ—Ä–æ—à–æ,  —á–µ–º —É–≤–ª–µ–∫–∞–µ—Ç–µ—Å—å?   ', ' –Ø –±–µ–≥–∞—é –ø–æ —É—Ç—Ä–∞–º –∞ —Ç—ã?   ', ' –ï—Å—Ç—å –ª—é–±–∏–º—ã–µ –≤–µ—â–∏ –∏–ª–∏ –µ–¥–∞ ?   ', ' –ó–∞–Ω—è—Ç ?   ', ' –Ø –ª—é–±–ª—é –ø–µ—Ç—å –≤ –∫–∞—Ä–∞–æ–∫–µ)   ', ' –ö—Ä—É—Ç–æ )   ', ' –õ—é–±–ª—é –≥–æ—Ç–æ–≤–∏—Ç—å –ø–∞—Å—Ç—É,  —É –º–µ–Ω—è –∫–ª–∞—Å—Å–Ω–æ –ø–æ–ª—É—á–∞–µ—Ç—Å—è!   ', ' –õ—é–±–∏—à—å –≥–æ—Ç–æ–≤–∏—Ç—å?   ', ' –≠—Ç–æ —Ö–æ—Ä–æ—à–æ   ', ' –Ø –Ω–µ —ç–∫—Å–ø–µ—Ä—Ç   ', ' –Ø –ª—é–±–ª—é –µ—Å—Ç—å –∞—Ä–±—É–∑  ']\n",
      "[' ', ' –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ   ', ' –Ø –õ–µ—à–∞   ', ' –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ   ', ' –Ø –ï–≥–æ—Ä   ', ' –Ø —É—á—É—Å—å –≤ 6 –∫–ª–∞—Å—Å–µ   ', ' –ê –º–Ω–µ 30 –∏ —è —É–∂–µ —Ä–∞–±–æ—Ç–∞—é   ', ' –ê —è —Ç–æ–∂–µ —Ö–æ—á—É. –ù–∞ –º–∞—à–∏–Ω—É —Å–∫–æ–ø–∏—Ç—å.   ', ' –ü—Ä–∞–≤–¥–∞ –º–Ω–µ –Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –º–æ—è —Ä–∞–±–æ—Ç–∞   ', ' –ü–æ—á–µ–º—É?   ', ' –ú–∞–ª–æ –ø–ª–∞—Ç—è—Ç   ', ' –ù–∞ —Å–µ–º—å—é –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç   ', ' –ñ–µ–Ω–∞ –∏ —Ç—Ä–æ–µ –¥–µ—Ç–µ–π   ', ' –ê... –∞ —è –Ω–∞ –º–∞—à–∏–Ω—É...   ', ' –û–≥–æ  ']\n",
      "[' ', ' –ü—Ä–∏–≤–µ—Ç!   ', ' –ü—Ä–∏–≤–µ—Ç!   ', ' –ö–∞–∫ —Ç–≤–æ–∏ –¥–µ–ª–∞?   ', ' –ù–æ—Ä–º–∞–ª—å–Ω–æ, –≥–æ—Ç–æ–≤–ª—é—Å—å –∫–æ —Å–Ω—É. –ó–∞–≤—Ç—Ä–∞ —Å–Ω–æ–≤–∞ –≤ —à–∫–æ–ª—É . –ù–µ –ª—é–±–ª—é —É—á–∏—Ç—å—Å—è.   ', ' –ê —Ç–≤–æ–∏ –∫–∞–∫?   ', ' –í—Å—ë —Ö–æ—Ä–æ—à–æ,—Å–ø–∞—Ç—å –Ω–µ —Ö–æ—á–µ—Ç—Å—è,–¥—É–º–∞—é —Ñ–∏–ª—å–º –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å   ', ' –ö–∞–∫–æ–π —Ñ–∏–ª—å–º?   ', ' –ï—â—ë –Ω–µ —Ä–µ—à–∏–ª–∞, –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–µ—Ç–µ–∫—Ç–∏–≤ –∫–∞–∫–æ–π –Ω–∏–±—É–¥—å. –ê –∫–∞–∫ –≤ —à–∫–æ–ª–µ —É —Ç–µ–±—è?   ', ' –•–æ—Ä–æ—à–æ, –µ—â—ë —É—á—É—Å—å, –Ω–æ —Å–∫–æ—Ä–æ –∑–∞–∫–æ–Ω—á—É. –£–∂–µ –º–µ—á—Ç–∞—é —Ä–∞–±–æ—Ç–∞—Ç—å , –∞ –Ω–µ —Å–∏–¥–µ—Ç—å –∑–∞ —É—á–µ–±–Ω–∏–∫–∞–º–∏. –ê —Ç—ã —Ä–∞–±–æ—Ç–∞–µ—à—å –∏–ª–∏ —É—á–∏—à—å—Å—è –µ—â—ë?   ', ' –ê —è —Ä–∞–±–æ—Ç–∞—é, –º–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –º–æ—è —Ä–∞–±–æ—Ç–∞, –∫–µ–º –ø–ª–∞–Ω–∏—Ä—É–µ—à—å —Ä–∞–±–æ—Ç–∞—Ç—å?   ', ' –•–æ—á—É –±—ã—Ç—å –ø—Å–∏—Ö–æ–ª–æ–≥–æ–º. –ê –∫–µ–º —Ç—ã —Ä–∞–±–æ—Ç–∞–µ—à—å?   ', ' –ù–µ –ø–æ–≤–µ—Ä–∏—à—å....—è –ø—Å–∏—Ö–æ–ª–æ–≥   ', ' –ö—Ä—É—Ç–æ! –ò –∫–∞–∫ —Ç–µ–±–µ?   ', ' –ú–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è,—è –ª—é–±–ª—é —Å–≤–æ—é —Ä–∞–±–æ—Ç—É.   ', ' –≠—Ç–æ –∫–ª–∞—Å—Å–Ω–æ. –•–æ—á—É —Ç–∞–∫–∂–µ. –ê —Ç—ã –æ–¥–Ω–∞ –∂–∏–≤–µ—à—å?   ', ' –ù–µ—Ç,—è –∂–∏–≤—É —Å –º–∞–º–æ–π,–∞ —Ç—ã?   ', ' –Ø —Ç–æ–∂–µ —Å —Ä–æ–¥–∏—Ç–µ–ª—è–º–∏ –∂–∏–≤—É, –æ–±–æ–∂–∞—é –∏—Ö. –ù–æ –∏–Ω–æ–≥–¥–∞ —Ö–æ—á–µ—Ç—Å—è –ø–æ–∂–∏—Ç—å –æ–¥–Ω–æ–π.   ', ' –ú–Ω–µ —Ç–æ–∂–µ, —è –ª—é–±–ª—é –±—ã—Ç—å –¥–æ–º–∞ –æ–¥–Ω–∞, –º–Ω–µ —ç–∏–æ —á–∞—Å—Ç–æ —É–¥–∞—ë—Ç—Å—è , –º—ã —Å –º–∞–º–æ–π —Ä–∞–±–æ—Ç–∞–µ–º –≤ —Ä–∞–∑–Ω–æ–µ –≤—Ä–µ–º—è, –∞ –≤ –∫–∞–∫–æ–º –≥–æ—Ä–æ–¥–µ —Ç—ã –∂–∏–≤—ë—à—å?   ', ' –ê —É –º–µ–Ω—è –º–∞–º–∞ –¥–æ–º–æ—Ö–æ–∑—è–π–∫–∞, –ø–æ—ç—Ç–æ–º—É —Ä–µ–¥–∫–æ –±—ã–≤–∞—é –¥–æ–º–∞ –æ–¥–Ω–∞. –í –ü–∏—Ç–µ—Ä–µ, –∞ —Ç—ã?   ', ' –ê —è –≤ –†–æ—Å—Ç–æ–≤–µ –Ω–∞ –î–æ–Ω—É.   ', ' –•–æ—á—É —Ç–∞–º –ø–æ–±—ã–≤–∞—Ç—å.   ', ' –õ–∞–¥–Ω–æ, –º–Ω–µ –ø–æ—Ä–∞ –ª–æ–∂–∏—Ç—å—Å—è   ', ' –†–∞–¥–∞ –±—ã–ª–∞ –ø–æ–±–æ–ª—Ç–∞—Ç—å!   ', ' –°–ø–æ–∫–æ–π–Ω–æ–π –Ω–æ—á–∏   ', ' –ü–æ–∑–¥–Ω–æ —É–∂–µ –º–æ–∂–µ—Ç –¥–æ –∑–∞–≤—Ç—Ä–∞? –°–ü–û–ö–û–ô–ù–û–ô –ù–û–ß–ò, –ü–†–ò–ï–ó–ñ–ê–ô –í –ì–û–°–¢–ò  ']\n"
     ]
    }
   ],
   "source": [
    "for i in data['dialogue'].head():\n",
    "    print(re.split(r'–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å \\d:', re.sub('<..*?>', ' ' , i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sNIKlTrMzszq"
   },
   "outputs": [],
   "source": [
    "data['dialogue_list']= data['dialogue'].apply(lambda x: re.split(r'–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ', re.sub('\\s\\s+',' ',re.sub('<..*?>', ' ' , x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "wHPH3mEQAu3T",
    "outputId": "99450f6e-5a61-41d3-9074-a46eedef809b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '2: –ü—Ä–∏–≤–µ—Ç) —Ä–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ ', '1: –ü—Ä–∏–≤–µ—Ç) –ø–æ–¥ –≤–∫—É—Å–Ω—ã–π –∫–æ—Ñ–µ–µ–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–æ–±–æ–ª—Ç–∞—Ç—å –ø–æ—è–≤–∏–ª–æ—Å—å ) ', '2: –ß—Ç–æ —á–∏—Ç–∞–µ—à—å? –ú–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –∫–ª–∞—Å—Å–∏–∫–∞ ', '2: –Ø —Ç–æ–∂–µ –ª—é–±–ª—é –ø–æ–æ–±—â–∞—Ç—å—Å—è ', '1: –õ—é–±–ª—é –∂–∏–≤–æ—Ç–Ω—ã—Ö, –ø—Ä–æ—Å—Ç–æ –æ–±–æ–∂–∞—é, –∫–∞–∫ –∏ —Å–≤–æ—é —Ä–∞–±–æ—Ç—É) ', '1: –Ø —Ñ–∞–Ω—Ç–∞—Å—Ç–∏–∫—É –ª—é–±–ª—é ', '2: –ê —è –≤—ã—Ä–∞—â–∏–≤–∞—é —Ñ–∏–∞–ª–∫–∏ ', '2: –ò –≤–µ–¥—É –∑–¥–æ—Ä–æ–≤—ã–π –∏ –∞–∫—Ç–∏–≤–Ω—ã–π –æ–±—Ä–∞–∑ –∂–∏–∑–Ω–∏! ', '1: –£—Ö —Ç—ã, –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ. ', '2: –¢—ã —Å–ª—É—á–∞–π–Ω–æ –Ω–µ –ø—Ä–∏–Ω—Ü –Ω–∞ –±–µ–ª–æ–º –∫–æ–Ω–µ? –Ø –µ–≥–æ –æ—á–µ–Ω—å –∂–¥—É .. ', '1: –ê —É –º–µ–Ω—è –∏–∑ —Ö–æ–±–±–∏ –∫–∞–∂–¥—É—é –Ω–µ–¥–µ–ª—é —Ç—É—Å–∏—Ç—å —Å –º–æ–∏–º –ª—É—á—à–∏–º –¥—Ä—É–≥–æ–º) ']\n",
      "[' ', '1: –ü—Ä–∏–≤–µ—Ç! ', '2: –ü—Ä–∏–≤–µ—Ç,–ö–∞–∫ –∂–∏–∑–Ω—å? ', '1: –û—Ç–ª–∏—á–Ω–æ) –°–æ–ª–Ω—ã—à–∫–æ —Å–≤–µ—Ç–∏—Ç, –ø—Ç–∏—á–∫–∏ –ø–æ—é—Ç! ', '2: –Ø –≤–æ—Ç —Å–µ–≥–æ–¥–Ω—è –ø–æ–Ω—è–ª, —á—Ç–æ –º–µ–Ω—è —Ç—É–ø–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç, –≤—Å–µ–º –Ω—É–∂–Ω—ã –æ—Ç –º–µ–Ω—è –ª–∏—à—å –¥–µ–Ω—å–≥–∏, –Ω–µ–Ω–∞–≤–∏–∂—É –ª—é–¥–µ–π ', '2: –ß–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è –ø–æ –∂–∏–∑–Ω–∏, —è –≤–æ—Ç –±–∏–∑–Ω–µ—Å–º–µ–Ω. ', '1: –ê —è –≤–æ—Ç —É—á—É –¥–µ—Ç–µ–π, —Ä–∞–±–æ—Ç–∞—é —Å –Ω–∞—á–∞–ª—å–Ω—ã–º–∏ –∫–ª–∞—Å—Å–∞–º–∏ ', '1: –ù–µ –≤—Å–µ –ª—é–¥–∏ —Ç–∞–∫–∏–µ, –∫–∞–∫ —Ç—ã –≥–æ–≤–æ—Ä–∏—à—å ', '1: –ü–æ–º–∏–º–æ —Ä–∞–±–æ—Ç—ã —á–µ–º –µ—â–µ —Ç—ã –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è? ', '2: –ö —Å–≤–∞–¥—å–±–µ –≥–æ—Ç–æ–≤–ª—é—Å—å ', '2: –ê —Ç—ã? ', '1: –í–æ—Ç –≤–∏–¥–∏—à—å) –∑–Ω–∞—á–∏—Ç, –Ω–∞—à–µ–ª —Ç–∞–∫—É—é –∂–µ–Ω—â–∏–Ω—É, –∫–æ—Ç–æ—Ä–æ–π –Ω–µ –Ω—É–∂–Ω—ã –æ—Ç —Ç–µ–±—è –¥–µ–Ω—å–≥–∏ ', '2: –î–∞ —è –Ω–∞–¥–µ—é—Å—å –Ω–∞ —ç—Ç–æ,–ª—é–±–ª—é –µ–µ ']\n",
      "[' ', '1: –ü—Ä–∏–≤–µ—Ç ', '1: –ö–∞–∫ –¥–µ–ª–∞ ? ', '2: –î–æ–±—Ä—ã–π –¥–µ–Ω—å! ', '2: –•–æ—Ä–æ—à–æ, —á–µ–º —É–≤–ª–µ–∫–∞–µ—Ç–µ—Å—å? ', '1: –Ø –±–µ–≥–∞—é –ø–æ —É—Ç—Ä–∞–º –∞ —Ç—ã? ', '1: –ï—Å—Ç—å –ª—é–±–∏–º—ã–µ –≤–µ—â–∏ –∏–ª–∏ –µ–¥–∞ ? ', '1: –ó–∞–Ω—è—Ç ? ', '2: –Ø –ª—é–±–ª—é –ø–µ—Ç—å –≤ –∫–∞—Ä–∞–æ–∫–µ) ', '1: –ö—Ä—É—Ç–æ ) ', '2: –õ—é–±–ª—é –≥–æ—Ç–æ–≤–∏—Ç—å –ø–∞—Å—Ç—É, —É –º–µ–Ω—è –∫–ª–∞—Å—Å–Ω–æ –ø–æ–ª—É—á–∞–µ—Ç—Å—è! ', '2: –õ—é–±–∏—à—å –≥–æ—Ç–æ–≤–∏—Ç—å? ', '1: –≠—Ç–æ —Ö–æ—Ä–æ—à–æ ', '1: –Ø –Ω–µ —ç–∫—Å–ø–µ—Ä—Ç ', '1: –Ø –ª—é–±–ª—é –µ—Å—Ç—å –∞—Ä–±—É–∑ ']\n",
      "[' ', '2: –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ ', '2: –Ø –õ–µ—à–∞ ', '1: –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ ', '1: –Ø –ï–≥–æ—Ä ', '2: –Ø —É—á—É—Å—å –≤ 6 –∫–ª–∞—Å—Å–µ ', '1: –ê –º–Ω–µ 30 –∏ —è —É–∂–µ —Ä–∞–±–æ—Ç–∞—é ', '2: –ê —è —Ç–æ–∂–µ —Ö–æ—á—É. –ù–∞ –º–∞—à–∏–Ω—É —Å–∫–æ–ø–∏—Ç—å. ', '1: –ü—Ä–∞–≤–¥–∞ –º–Ω–µ –Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –º–æ—è —Ä–∞–±–æ—Ç–∞ ', '2: –ü–æ—á–µ–º—É? ', '1: –ú–∞–ª–æ –ø–ª–∞—Ç—è—Ç ', '1: –ù–∞ —Å–µ–º—å—é –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç ', '1: –ñ–µ–Ω–∞ –∏ —Ç—Ä–æ–µ –¥–µ—Ç–µ–π ', '2: –ê... –∞ —è –Ω–∞ –º–∞—à–∏–Ω—É... ', '2: –û–≥–æ ']\n",
      "[' ', '1: –ü—Ä–∏–≤–µ—Ç! ', '2: –ü—Ä–∏–≤–µ—Ç! ', '2: –ö–∞–∫ —Ç–≤–æ–∏ –¥–µ–ª–∞? ', '1: –ù–æ—Ä–º–∞–ª—å–Ω–æ, –≥–æ—Ç–æ–≤–ª—é—Å—å –∫–æ —Å–Ω—É. –ó–∞–≤—Ç—Ä–∞ —Å–Ω–æ–≤–∞ –≤ —à–∫–æ–ª—É . –ù–µ –ª—é–±–ª—é —É—á–∏—Ç—å—Å—è. ', '1: –ê —Ç–≤–æ–∏ –∫–∞–∫? ', '2: –í—Å—ë —Ö–æ—Ä–æ—à–æ,—Å–ø–∞—Ç—å –Ω–µ —Ö–æ—á–µ—Ç—Å—è,–¥—É–º–∞—é —Ñ–∏–ª—å–º –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å ', '1: –ö–∞–∫–æ–π —Ñ–∏–ª—å–º? ', '2: –ï—â—ë –Ω–µ —Ä–µ—à–∏–ª–∞, –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–µ—Ç–µ–∫—Ç–∏–≤ –∫–∞–∫–æ–π –Ω–∏–±—É–¥—å. –ê –∫–∞–∫ –≤ —à–∫–æ–ª–µ —É —Ç–µ–±—è? ', '1: –•–æ—Ä–æ—à–æ, –µ—â—ë —É—á—É—Å—å, –Ω–æ —Å–∫–æ—Ä–æ –∑–∞–∫–æ–Ω—á—É. –£–∂–µ –º–µ—á—Ç–∞—é —Ä–∞–±–æ—Ç–∞—Ç—å , –∞ –Ω–µ —Å–∏–¥–µ—Ç—å –∑–∞ —É—á–µ–±–Ω–∏–∫–∞–º–∏. –ê —Ç—ã —Ä–∞–±–æ—Ç–∞–µ—à—å –∏–ª–∏ —É—á–∏—à—å—Å—è –µ—â—ë? ', '2: –ê —è —Ä–∞–±–æ—Ç–∞—é, –º–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –º–æ—è —Ä–∞–±–æ—Ç–∞, –∫–µ–º –ø–ª–∞–Ω–∏—Ä—É–µ—à—å —Ä–∞–±–æ—Ç–∞—Ç—å? ', '1: –•–æ—á—É –±—ã—Ç—å –ø—Å–∏—Ö–æ–ª–æ–≥–æ–º. –ê –∫–µ–º —Ç—ã —Ä–∞–±–æ—Ç–∞–µ—à—å? ', '2: –ù–µ –ø–æ–≤–µ—Ä–∏—à—å....—è –ø—Å–∏—Ö–æ–ª–æ–≥ ', '1: –ö—Ä—É—Ç–æ! –ò –∫–∞–∫ —Ç–µ–±–µ? ', '2: –ú–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è,—è –ª—é–±–ª—é —Å–≤–æ—é —Ä–∞–±–æ—Ç—É. ', '1: –≠—Ç–æ –∫–ª–∞—Å—Å–Ω–æ. –•–æ—á—É —Ç–∞–∫–∂–µ. –ê —Ç—ã –æ–¥–Ω–∞ –∂–∏–≤–µ—à—å? ', '2: –ù–µ—Ç,—è –∂–∏–≤—É —Å –º–∞–º–æ–π,–∞ —Ç—ã? ', '1: –Ø —Ç–æ–∂–µ —Å —Ä–æ–¥–∏—Ç–µ–ª—è–º–∏ –∂–∏–≤—É, –æ–±–æ–∂–∞—é –∏—Ö. –ù–æ –∏–Ω–æ–≥–¥–∞ —Ö–æ—á–µ—Ç—Å—è –ø–æ–∂–∏—Ç—å –æ–¥–Ω–æ–π. ', '2: –ú–Ω–µ —Ç–æ–∂–µ, —è –ª—é–±–ª—é –±—ã—Ç—å –¥–æ–º–∞ –æ–¥–Ω–∞, –º–Ω–µ —ç–∏–æ —á–∞—Å—Ç–æ —É–¥–∞—ë—Ç—Å—è , –º—ã —Å –º–∞–º–æ–π —Ä–∞–±–æ—Ç–∞–µ–º –≤ —Ä–∞–∑–Ω–æ–µ –≤—Ä–µ–º—è, –∞ –≤ –∫–∞–∫–æ–º –≥–æ—Ä–æ–¥–µ —Ç—ã –∂–∏–≤—ë—à—å? ', '1: –ê —É –º–µ–Ω—è –º–∞–º–∞ –¥–æ–º–æ—Ö–æ–∑—è–π–∫–∞, –ø–æ—ç—Ç–æ–º—É —Ä–µ–¥–∫–æ –±—ã–≤–∞—é –¥–æ–º–∞ –æ–¥–Ω–∞. –í –ü–∏—Ç–µ—Ä–µ, –∞ —Ç—ã? ', '2: –ê —è –≤ –†–æ—Å—Ç–æ–≤–µ –Ω–∞ –î–æ–Ω—É. ', '1: –•–æ—á—É —Ç–∞–º –ø–æ–±—ã–≤–∞—Ç—å. ', '1: –õ–∞–¥–Ω–æ, –º–Ω–µ –ø–æ—Ä–∞ –ª–æ–∂–∏—Ç—å—Å—è ', '1: –†–∞–¥–∞ –±—ã–ª–∞ –ø–æ–±–æ–ª—Ç–∞—Ç—å! ', '1: –°–ø–æ–∫–æ–π–Ω–æ–π –Ω–æ—á–∏ ', '2: –ü–æ–∑–¥–Ω–æ —É–∂–µ –º–æ–∂–µ—Ç –¥–æ –∑–∞–≤—Ç—Ä–∞? –°–ü–û–ö–û–ô–ù–û–ô –ù–û–ß–ò, –ü–†–ò–ï–ó–ñ–ê–ô –í –ì–û–°–¢–ò ']\n"
     ]
    }
   ],
   "source": [
    "for i in data['dialogue_list'].head():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eSlq41Bb0Eu6"
   },
   "outputs": [],
   "source": [
    "data['dialogue_list'] = data['dialogue_list'].apply(lambda x: list(filter(lambda s: s.strip() != '', x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "id": "p4xNkjZc0mtC",
    "outputId": "51007680-aa6f-4ddb-b2f1-04c5706c103b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1: –ü—Ä–∏–≤–µ—Ç! ',\n",
       " '2: –ü—Ä–∏–≤–µ—Ç,–ö–∞–∫ –∂–∏–∑–Ω—å? ',\n",
       " '1: –û—Ç–ª–∏—á–Ω–æ) –°–æ–ª–Ω—ã—à–∫–æ —Å–≤–µ—Ç–∏—Ç, –ø—Ç–∏—á–∫–∏ –ø–æ—é—Ç! ',\n",
       " '2: –Ø –≤–æ—Ç —Å–µ–≥–æ–¥–Ω—è –ø–æ–Ω—è–ª, —á—Ç–æ –º–µ–Ω—è —Ç—É–ø–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç, –≤—Å–µ–º –Ω—É–∂–Ω—ã –æ—Ç –º–µ–Ω—è –ª–∏—à—å –¥–µ–Ω—å–≥–∏, –Ω–µ–Ω–∞–≤–∏–∂—É –ª—é–¥–µ–π ',\n",
       " '2: –ß–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è –ø–æ –∂–∏–∑–Ω–∏, —è –≤–æ—Ç –±–∏–∑–Ω–µ—Å–º–µ–Ω. ',\n",
       " '1: –ê —è –≤–æ—Ç —É—á—É –¥–µ—Ç–µ–π, —Ä–∞–±–æ—Ç–∞—é —Å –Ω–∞—á–∞–ª—å–Ω—ã–º–∏ –∫–ª–∞—Å—Å–∞–º–∏ ',\n",
       " '1: –ù–µ –≤—Å–µ –ª—é–¥–∏ —Ç–∞–∫–∏–µ, –∫–∞–∫ —Ç—ã –≥–æ–≤–æ—Ä–∏—à—å ',\n",
       " '1: –ü–æ–º–∏–º–æ —Ä–∞–±–æ—Ç—ã —á–µ–º –µ—â–µ —Ç—ã –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è? ',\n",
       " '2: –ö —Å–≤–∞–¥—å–±–µ –≥–æ—Ç–æ–≤–ª—é—Å—å ',\n",
       " '2: –ê —Ç—ã? ',\n",
       " '1: –í–æ—Ç –≤–∏–¥–∏—à—å) –∑–Ω–∞—á–∏—Ç, –Ω–∞—à–µ–ª —Ç–∞–∫—É—é –∂–µ–Ω—â–∏–Ω—É, –∫–æ—Ç–æ—Ä–æ–π –Ω–µ –Ω—É–∂–Ω—ã –æ—Ç —Ç–µ–±—è –¥–µ–Ω—å–≥–∏ ',\n",
       " '2: –î–∞ —è –Ω–∞–¥–µ—é—Å—å –Ω–∞ —ç—Ç–æ,–ª—é–±–ª—é –µ–µ ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['dialogue_list'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jAao2hpB1Gk9"
   },
   "outputs": [],
   "source": [
    "def add_seq_pers(x):\n",
    "    cur_pers = ''\n",
    "    new_list = []\n",
    "    cur_str = ''\n",
    "    for i in x:\n",
    "        if i[:2] != cur_pers:\n",
    "          #                              —Å–º–∞–π–ª–∏–∫–∏                       –¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã .       —É–±–∏—Ä–∞–µ—Ç –¥–≤–∞ –∑–Ω–∞–∫–∞ —Ç–∏–ø–∞ ? .              —Å—Ç–∞–≤–∏—Ç –ø—Ä–æ–±–µ–ª –º–µ–∂–¥—É —Å–ª–æ–≤–æ–º –∏ –∑–Ω–∞–∫–æ–º\n",
    "            new_list.append(re.sub(r'\\d+','',re.sub(r'[\\?\\!\\:\\)\\(\\-]{2,5}','',re.sub(r'\\s\\s+',' ', re.sub(r'([\\!\\.?,\\)\\(\\:\\-)])\\s*([\\!\\.?,\\)\\(\\:\\-)])+','.',re.sub(r'([\\!\\.?,\\)\\(\\:\\-)]+)', r' \\1',re.sub(r'[\\)\\()]','.', cur_str.lower()).strip()))))))\n",
    "            cur_str = i[2:]\n",
    "            cur_pers = i[:2]    \n",
    "        else: \n",
    "            cur_str += ' . ' +  i[2:] \n",
    "    return new_list[1:]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yWVW_Rn08jm3"
   },
   "outputs": [],
   "source": [
    "data['dialogue_list'] = data['dialogue_list'].apply(add_seq_pers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "OWslVEEJ8rFA",
    "outputId": "c680d280-bb3a-42c5-c6b5-5b28901f7ab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–ø—Ä–∏–≤–µ—Ç . —Ä–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ', '–ø—Ä–∏–≤–µ—Ç . –ø–æ–¥ –≤–∫—É—Å–Ω—ã–π –∫–æ—Ñ–µ–µ–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–æ–±–æ–ª—Ç–∞—Ç—å –ø–æ—è–≤–∏–ª–æ—Å—å .', '—á—Ç–æ —á–∏—Ç–∞–µ—à—å ? –º–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –∫–ª–∞—Å—Å–∏–∫–∞ . —è —Ç–æ–∂–µ –ª—é–±–ª—é –ø–æ–æ–±—â–∞—Ç—å—Å—è', '–ª—é–±–ª—é –∂–∏–≤–æ—Ç–Ω—ã—Ö , –ø—Ä–æ—Å—Ç–æ –æ–±–æ–∂–∞—é , –∫–∞–∫ –∏ —Å–≤–æ—é —Ä–∞–±–æ—Ç—É . —è —Ñ–∞–Ω—Ç–∞—Å—Ç–∏–∫—É –ª—é–±–ª—é', '–∞ —è –≤—ã—Ä–∞—â–∏–≤–∞—é —Ñ–∏–∞–ª–∫–∏ . –∏ –≤–µ–¥—É –∑–¥–æ—Ä–æ–≤—ã–π –∏ –∞–∫—Ç–∏–≤–Ω—ã–π –æ–±—Ä–∞–∑ –∂–∏–∑–Ω–∏ !', '—É—Ö —Ç—ã , –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ .', '—Ç—ã —Å–ª—É—á–∞–π–Ω–æ –Ω–µ –ø—Ä–∏–Ω—Ü –Ω–∞ –±–µ–ª–æ–º –∫–æ–Ω–µ ? —è –µ–≥–æ –æ—á–µ–Ω—å –∂–¥—É .']\n",
      "['–ø—Ä–∏–≤–µ—Ç !', '–ø—Ä–∏–≤–µ—Ç ,–∫–∞–∫ –∂–∏–∑–Ω—å ?', '–æ—Ç–ª–∏—á–Ω–æ . —Å–æ–ª–Ω—ã—à–∫–æ —Å–≤–µ—Ç–∏—Ç , –ø—Ç–∏—á–∫–∏ –ø–æ—é—Ç !', '—è –≤–æ—Ç —Å–µ–≥–æ–¥–Ω—è –ø–æ–Ω—è–ª , —á—Ç–æ –º–µ–Ω—è —Ç—É–ø–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç , –≤—Å–µ–º –Ω—É–∂–Ω—ã –æ—Ç –º–µ–Ω—è –ª–∏—à—å –¥–µ–Ω—å–≥–∏ , –Ω–µ–Ω–∞–≤–∏–∂—É –ª—é–¥–µ–π . —á–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è –ø–æ –∂–∏–∑–Ω–∏ , —è –≤–æ—Ç –±–∏–∑–Ω–µ—Å–º–µ–Ω .', '–∞ —è –≤–æ—Ç —É—á—É –¥–µ—Ç–µ–π , —Ä–∞–±–æ—Ç–∞—é —Å –Ω–∞—á–∞–ª—å–Ω—ã–º–∏ –∫–ª–∞—Å—Å–∞–º–∏ . –Ω–µ –≤—Å–µ –ª—é–¥–∏ —Ç–∞–∫–∏–µ , –∫–∞–∫ —Ç—ã –≥–æ–≤–æ—Ä–∏—à—å . –ø–æ–º–∏–º–æ —Ä–∞–±–æ—Ç—ã —á–µ–º –µ—â–µ —Ç—ã –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è ?', '–∫ —Å–≤–∞–¥—å–±–µ –≥–æ—Ç–æ–≤–ª—é—Å—å . –∞ —Ç—ã ?', '–≤–æ—Ç –≤–∏–¥–∏—à—å . –∑–Ω–∞—á–∏—Ç , –Ω–∞—à–µ–ª —Ç–∞–∫—É—é –∂–µ–Ω—â–∏–Ω—É , –∫–æ—Ç–æ—Ä–æ–π –Ω–µ –Ω—É–∂–Ω—ã –æ—Ç —Ç–µ–±—è –¥–µ–Ω—å–≥–∏']\n",
      "['–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', '–¥–æ–±—Ä—ã–π –¥–µ–Ω—å . —Ö–æ—Ä–æ—à–æ , —á–µ–º —É–≤–ª–µ–∫–∞–µ—Ç–µ—Å—å ?', '—è –±–µ–≥–∞—é –ø–æ —É—Ç—Ä–∞–º –∞ —Ç—ã . –µ—Å—Ç—å –ª—é–±–∏–º—ã–µ –≤–µ—â–∏ –∏–ª–∏ –µ–¥–∞ . –∑–∞–Ω—è—Ç ?', '—è –ª—é–±–ª—é –ø–µ—Ç—å –≤ –∫–∞—Ä–∞–æ–∫–µ .', '–∫—Ä—É—Ç–æ .', '–ª—é–±–ª—é –≥–æ—Ç–æ–≤–∏—Ç—å –ø–∞—Å—Ç—É , —É –º–µ–Ω—è –∫–ª–∞—Å—Å–Ω–æ –ø–æ–ª—É—á–∞–µ—Ç—Å—è . –ª—é–±–∏—à—å –≥–æ—Ç–æ–≤–∏—Ç—å ?']\n",
      "['–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ . —è –ª–µ—à–∞', '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ . —è –µ–≥–æ—Ä', '—è —É—á—É—Å—å –≤  –∫–ª–∞—Å—Å–µ', '–∞ –º–Ω–µ  –∏ —è —É–∂–µ —Ä–∞–±–æ—Ç–∞—é', '–∞ —è —Ç–æ–∂–µ —Ö–æ—á—É . –Ω–∞ –º–∞—à–∏–Ω—É —Å–∫–æ–ø–∏—Ç—å .', '–ø—Ä–∞–≤–¥–∞ –º–Ω–µ –Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –º–æ—è —Ä–∞–±–æ—Ç–∞', '–ø–æ—á–µ–º—É ?', '–º–∞–ª–æ –ø–ª–∞—Ç—è—Ç . –Ω–∞ —Å–µ–º—å—é –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç . –∂–µ–Ω–∞ –∏ —Ç—Ä–æ–µ –¥–µ—Ç–µ–π']\n",
      "['–ø—Ä–∏–≤–µ—Ç !', '–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ —Ç–≤–æ–∏ –¥–µ–ª–∞ ?', '–Ω–æ—Ä–º–∞–ª—å–Ω–æ , –≥–æ—Ç–æ–≤–ª—é—Å—å –∫–æ —Å–Ω—É . –∑–∞–≤—Ç—Ä–∞ —Å–Ω–æ–≤–∞ –≤ —à–∫–æ–ª—É . –Ω–µ –ª—é–±–ª—é —É—á–∏—Ç—å—Å—è . –∞ —Ç–≤–æ–∏ –∫–∞–∫ ?', '–≤—Å—ë —Ö–æ—Ä–æ—à–æ ,—Å–ø–∞—Ç—å –Ω–µ —Ö–æ—á–µ—Ç—Å—è ,–¥—É–º–∞—é —Ñ–∏–ª—å–º –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å', '–∫–∞–∫–æ–π —Ñ–∏–ª—å–º ?', '–µ—â—ë –Ω–µ —Ä–µ—à–∏–ª–∞ , –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–µ—Ç–µ–∫—Ç–∏–≤ –∫–∞–∫–æ–π –Ω–∏–±—É–¥—å . –∞ –∫–∞–∫ –≤ —à–∫–æ–ª–µ —É —Ç–µ–±—è ?', '—Ö–æ—Ä–æ—à–æ , –µ—â—ë —É—á—É—Å—å , –Ω–æ —Å–∫–æ—Ä–æ –∑–∞–∫–æ–Ω—á—É . —É–∂–µ –º–µ—á—Ç–∞—é —Ä–∞–±–æ—Ç–∞—Ç—å , –∞ –Ω–µ —Å–∏–¥–µ—Ç—å –∑–∞ —É—á–µ–±–Ω–∏–∫–∞–º–∏ . –∞ —Ç—ã —Ä–∞–±–æ—Ç–∞–µ—à—å –∏–ª–∏ —É—á–∏—à—å—Å—è –µ—â—ë ?', '–∞ —è —Ä–∞–±–æ—Ç–∞—é , –º–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –º–æ—è —Ä–∞–±–æ—Ç–∞ , –∫–µ–º –ø–ª–∞–Ω–∏—Ä—É–µ—à—å —Ä–∞–±–æ—Ç–∞—Ç—å ?', '—Ö–æ—á—É –±—ã—Ç—å –ø—Å–∏—Ö–æ–ª–æ–≥–æ–º . –∞ –∫–µ–º —Ç—ã —Ä–∞–±–æ—Ç–∞–µ—à—å ?', '–Ω–µ –ø–æ–≤–µ—Ä–∏—à—å .—è –ø—Å–∏—Ö–æ–ª–æ–≥', '–∫—Ä—É—Ç–æ ! –∏ –∫–∞–∫ —Ç–µ–±–µ ?', '–º–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è ,—è –ª—é–±–ª—é —Å–≤–æ—é —Ä–∞–±–æ—Ç—É .', '—ç—Ç–æ –∫–ª–∞—Å—Å–Ω–æ . —Ö–æ—á—É —Ç–∞–∫–∂–µ . –∞ —Ç—ã –æ–¥–Ω–∞ –∂–∏–≤–µ—à—å ?', '–Ω–µ—Ç ,—è –∂–∏–≤—É —Å –º–∞–º–æ–π ,–∞ —Ç—ã ?', '—è —Ç–æ–∂–µ —Å —Ä–æ–¥–∏—Ç–µ–ª—è–º–∏ –∂–∏–≤—É , –æ–±–æ–∂–∞—é –∏—Ö . –Ω–æ –∏–Ω–æ–≥–¥–∞ —Ö–æ—á–µ—Ç—Å—è –ø–æ–∂–∏—Ç—å –æ–¥–Ω–æ–π .', '–º–Ω–µ —Ç–æ–∂–µ , —è –ª—é–±–ª—é –±—ã—Ç—å –¥–æ–º–∞ –æ–¥–Ω–∞ , –º–Ω–µ —ç–∏–æ —á–∞—Å—Ç–æ —É–¥–∞—ë—Ç—Å—è , –º—ã —Å –º–∞–º–æ–π —Ä–∞–±–æ—Ç–∞–µ–º –≤ —Ä–∞–∑–Ω–æ–µ –≤—Ä–µ–º—è , –∞ –≤ –∫–∞–∫–æ–º –≥–æ—Ä–æ–¥–µ —Ç—ã –∂–∏–≤—ë—à—å ?', '–∞ —É –º–µ–Ω—è –º–∞–º–∞ –¥–æ–º–æ—Ö–æ–∑—è–π–∫–∞ , –ø–æ—ç—Ç–æ–º—É —Ä–µ–¥–∫–æ –±—ã–≤–∞—é –¥–æ–º–∞ –æ–¥–Ω–∞ . –≤ –ø–∏—Ç–µ—Ä–µ , –∞ —Ç—ã ?', '–∞ —è –≤ —Ä–æ—Å—Ç–æ–≤–µ –Ω–∞ –¥–æ–Ω—É .', '—Ö–æ—á—É —Ç–∞–º –ø–æ–±—ã–≤–∞—Ç—å . –ª–∞–¥–Ω–æ , –º–Ω–µ –ø–æ—Ä–∞ –ª–æ–∂–∏—Ç—å—Å—è . —Ä–∞–¥–∞ –±—ã–ª–∞ –ø–æ–±–æ–ª—Ç–∞—Ç—å . —Å–ø–æ–∫–æ–π–Ω–æ–π –Ω–æ—á–∏']\n",
      "['–ø—Ä–∏–≤–µ—Ç !', '–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ .', '—É –º–µ–Ω—è –≤—Å–µ –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ . –∞ —Ç–≤–æ–∏ –¥–µ–ª–∞ –∫–∞–∫ ? —á–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è –ø–æ –∂–∏–∑–Ω–∏ . ?', '—Ä–∞–¥–∞ –Ω–æ–≤–æ–º—É –∑–Ω–∞–∫–æ–º—Å—Ç–≤—É ! —É –º–µ–Ω—è —Ç–æ–∂–µ –≤—Å—ë –Ω–µ–ø–ª–æ—Ö–æ . –Ω–µ–¥–∞–≤–Ω–æ –Ω–∞—à–ª–∞ —Ä–∞–±–æ—Ç—É –ø–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏ . —è –¥–∏–∑–∞–π–Ω–µ—Ä . –∞ —Ç—ã —á–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è . —Ç—ã –æ—Ç–∫—É–¥–∞ ?', '—è –ø—Ä–æ–¥–∞–≤–µ—Ü , –≤—ã—Ä–∞—â–∏–≤–∞–Ω–∏—é –æ–≤–æ—â–∏ –∏ —Ñ—Ä—É–∫—Ç—ã –Ω–∞ –¥–∞—á–µ –∏ –ø—Ä–æ–¥–∞—é –∏—Ö . —è –µ—â—ë –∫—Å—Ç–∞—Ç–∏ –∏ –¥–∞—á–Ω–∏—Ü–∞ . —è —Å —É–∫—Ä–∞–∏–Ω—ã . –∞ —Ç—ã –æ—Ç–∫—É–¥–∞ ?', '–∫—Ä—É—Ç–æ ! —è –∏–∑ –±–µ–ª–∞—Ä—É—Å–∏ , –º–∏–Ω—Å–∫', '—è –ø—Ä–æ–¥–∞–≤–µ—Ü , –≤—ã—Ä–∞—â–∏–≤–∞—é –æ–≤–æ—â–∏ –∏ —Ñ—Ä—É–∫—Ç—ã –Ω–∞ –¥–∞—á–µ –∏ –ø—Ä–æ–¥–∞—é –∏—Ö . —è –µ—â—ë –∫—Å—Ç–∞—Ç–∏ –∏ –¥–∞—á–Ω–∏—Ü–∞ . –∫–∞–∫ –∑–æ–≤—É—Ç —Ç–µ–±—è ?', '–∞ —è –º–µ—á—Ç–∞—é –∫—É–ø–∏—Ç—å –¥–∞—á—É , –Ω–æ –ø–æ–∫–∞ –Ω–µ –º–æ–≥—É —Å–µ–±–µ —ç—Ç–æ–≥–æ –ø–æ–∑–≤–æ–ª–∏—Ç—å . –∫–∞—Ç—è , –∞ —Ç–µ–±—è ?', '–∏—Ä–∞ ,–ø—Ä–∏—è—Ç–Ω–æ –ø–æ–∑–Ω–∞–∫–æ–º–∏—Ç—Å—è . –∞ —è –º–µ—á—Ç–∞—é –∂–∏—Ç—å –≤–æ–∑–ª–µ –º–æ—Ä—è .', '–∫—Å—Ç–∞—Ç–∏ , –±—ã–ª–∞ –≤ —É–∫—Ä–∞–∏–Ω–µ , –º–Ω–µ —Ç–∞–º –æ—á–µ–Ω—å –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å . —è –≤–æ–æ–±—â–µ –ª—é–±–ª—é –ø—É—Ç–µ—à–µ—Å—Ç–≤–æ–≤–∞—Ç—å', '–æ–±–æ–∂–∞—é –º–æ—Ä–µ .', '–ø—Ä–∏—è—Ç–Ω–æ –ø–æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è', '–≤ –∫–∞–∫–æ–º –≥–æ—Ä–æ–¥–µ —É–∫—Ä–∞–∏–Ω—ã —Ç—ã –±—ã–ª–∞ ?', '–æ , —è —Ç–æ–∂–µ –ª—é–±–ª—é –º–æ—Ä–µ . . –º–Ω–æ–≥–æ –≥–¥–µ , –∏ –≤ –∫—Ä—ã–º—É .—Ç–æ–≥–¥–∞ —ç—Ç–æ –±—ã–ª–∞ –µ—â—ë —É–∫—Ä–∞–∏–Ω–∞ .', '–∂–¥—É –Ω–µ –¥–æ–∂–¥—É—Å—å –ª–µ—Ç–∞ , —á—Ç–æ –±—ã –ø–æ–µ—Ö–∞—Ç—å –Ω–∞ –º–æ—Ä–µ üåä . –∫ —Å—Ç–∞—Ç–∏ , —Ç—ã –ª—é–±–∏—à—å —Å–æ–±–∞–∫ ?', '–º—ã –ø—É—Ç–µ—à–µ—Å—Ç–≤–æ–≤–∞–ª–∏ —Å –¥—Ä—É–∑—å—è–º–∏ –Ω–∞ –º–∞—à–∏–Ω–µ , –ø–æ—ç—Ç–æ–º—É –º–Ω–æ–≥–æ –≥–¥–µ –ø–æ–±—ã–≤–∞–ª–∏ . —Ö–æ—Ç—è —è –±–æ–ª—å—à–µ –ª—é–±–ª—é –ø–µ—à–∏–µ –ø—Ä–æ–≥—É–ª–∫–∏ .', '–ø–µ—à–∏–µ –ø—Ä–æ–≥—É–ª–∫–∏ —ç—Ç–æ –∑–¥–æ—Ä–æ–≤–æ .', '–æ –¥–∞ , —è –ª—é–±–ª—é –∂–∏–≤–æ—Ç–Ω—ã—Ö . –Ω–æ —è –±–æ–ª—å—à–µ –∫–æ—à–∞—Ç–Ω–∏—Ü–∞ . —É –º–µ–Ω—è –∫–æ—Ç –≤–µ–≥–∞—Å –∏ —á–µ—Ä–µ–ø–∞—Ö–∞ –º–∞—Ç–∏–ª—å–¥–∞ . –∞ —É —Ç–µ–±—è –µ—Å—Ç—å —Å–æ–±–∞–∫–∞ ?', '—É –º–µ–Ω—è –∞–∂ –¥–≤–µ —Å–æ–±–∞–∫–∏ .', '–∑–¥–æ—Ä–æ–≤–æ ! –∫–∞–∫ –∏—Ö –∑–æ–≤—É—Ç ?', '–∞–∑–∞ –∏ –≥–µ—Ä–¥–∞ , –¥–≤–µ –¥–µ–≤–æ—á–∫–∏ –¥–≤–æ—Ä–Ω—è–∂–∫–∏ . –ø–æ–¥–æ–±—Ä–∞–ª–∞ –∏—Ö –Ω–∞ —É–ª–∏—Ü–µ , –∫—Ç–æ –±—Ä–æ—Å–∏–ª —Å–æ–≤—Å–µ–º –º–∞–ª–µ–Ω—å–∫–∏—Ö , –ø—Ä–∏—à–ª–æ—Å—å –æ –Ω–∏—Ö –º–Ω–æ–≥–æ –∑–∞–±–æ—Ç–∏—Ç—å—Å—è . –ø–æ–¥–æ–±—Ä–∞–ª–∞ –∏—Ö –Ω–∞ —É–ª–∏—Ü–µ , –∫—Ç–æ - —Ç–æ –±—Ä–æ—Å–∏–ª —Å–æ–≤—Å–µ–º –º–∞–ª–µ–Ω—å–∫–∏—Ö , –ø—Ä–∏—à–ª–æ—Å—å –æ –Ω–∏—Ö –º–Ω–æ–≥–æ –∑–∞–±–æ—Ç–∏—Ç—å—Å—è .', '—è —Ç–æ–∂–µ . –ø–ª–∞–Ω–∏—Ä—É—é –Ω–æ–≤–æ–µ –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏–µ –ª–µ—Ç–æ–º . —è —É–∂–µ –ø–æ–±—ã–≤–∞–ª–∞ –≤  —Å—Ç—Ä–∞–Ω–∞—Ö . –∞ —Ç—ã –ª—é–±–∏—à—å –ø—É—Ç–µ—à–µ—Å—Ç–≤–æ–≤–∞—Ç—å . —Ç—ã –º–æ–ª–æ–¥–µ—Ü , —Å–ø–∞—Å–ª–∞ –¥–≤–µ –∂–∏–∑–Ω–∏ . —ç—Ç–æ –∑–¥–æ—Ä–æ–≤–æ', '–ø–æ–∫–∞ —á—Ç–æ –Ω–µ —É–¥–∞–≤–∞–ª–æ—Å—å –ø–æ–±—ã–≤–∞—Ç—å –≤ –¥—Ä—É–≥–∏—Ö —Å—Ç—Ä–∞–Ω–∞—Ö , –Ω–æ –Ω–∞ —ç—Ç–æ –ª–µ—Ç–æ –≥—Ä–∞–Ω–¥–∏–æ–∑–Ω—ã–µ –ø–ª–∞–Ω—ã .', '–∫–∞–∫–∏–µ ?', '–ø–æ–µ—Ö–∞—Ç—å —Å–Ω–∞—á–∞–ª–∞ –≤ –≥–µ—Ä–º–∞–Ω–∏—é , –∞ –ø–æ—Ç–æ–º –≤ —Ä–æ—Å—Å–∏—é –∫ —Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–∏–∫–∞–º', '–∫—Å—Ç–∞—Ç–∏ , –∫–æ–≥–¥–∞ —è –±—ã–ª–∞ –≤–æ –ª—å–≤–æ–≤–µ , —Ö–æ–¥–∏–ª–∞ –Ω–∞ –∫–æ–Ω—Ü–µ—Ä—Ç –æ–∫–µ–∞–Ω —ç–ª—å–∑–∏ . –æ—á–µ–Ω—å –ª—é–±–ª—é —ç—Ç—É –≥—Ä—É–ø–ø—É –∏ –≤–æ–æ–±—â–µ —Ä–æ–∫ . –∞ –∫–∞–∫—É—é –º—É–∑—ã–∫—É —Ç—ã —Å–ª—É—à–∞–µ—à—å ?', '–∞ —è —Ä–æ–∫ –Ω–µ –ª—é–±–ª—é , –º–Ω–µ –Ω—Ä–∞–≤–∏—Ç—å—Å—è –¥–∂–∞–∑ . –∞ –≤–æ–æ–±—â–µ —á–∞—Å—Ç–æ —Å–ª—É—à–∞—é –ø–æ–ø –∏ —Ä—ç–ø', '—è –±—ã–ª–∞ –≤ –≥–µ—Ä–º–∞–Ω–∏–∏ , –º–Ω–µ —Ç–∞–º –æ—á–µ–Ω—å –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å , –æ—Å–æ–±–µ–Ω–Ω–æ –∫—Ä–∞—Å–∏–≤—ã–µ –∑–∞–º–∫–∏ . –Ω—É –∏–∑ –¥–∂–∞–∑–∞ —Ä–æ–¥–∏–ª—Å—è —Ä–æ–∫ .']\n",
      "['–ø—Ä–∏–≤–µ—Ç', '–ø—Ä–∏–≤–µ—Ç', '–∫–∞–∫ –¥–µ–ª–∞ ? —è –∏ –Ω–æ—Ä–≤–µ–≥–∏–∏ ,–∞ —Ç—ã ?', '—Ö–æ—Ä–æ—à–æ , –∞ —É —Ç–µ–±—è –∫–∞–∫ ? —è –∏–∑ —Ä–æ—Å—Å–∏–∏ . –∫—Ç–æ –ø–æ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ —Ç—ã ?', '—Ç–æ–∂–µ —Ö–æ—Ä–æ—à–æ , —á–µ–≥–æ –Ω–µ —Å–ø–∏—à—å ?', '—Ä–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ . —Å—Ç–∏—Ä–∞—é –±–µ–ª—å–µ , –∂–¥—É .', '—è –Ω–µ —Ä–∞–±–æ—Ç–∞—é .', '–∞ –ø–æ—á–µ–º—É ?', '–∂–∏–≤—É –≤ –Ω–æ—Ä–≤–µ–≥–∏–∏ —Å  –ª–µ—Ç , —Å–µ–π—á–∞—Å –º–Ω–µ  , —É–µ—Ö–∞–ª–∏ —Å —Ä–æ–¥–∏—Ç–µ–ª—è–º–∏ , –æ—Ç—Ü—É –Ω–∞–¥–æ –±—ã–ª–æ –ø–æ —Ä–∞–±–æ—Ç–µ , –æ—Å—Ç–∞–ª–∏—Å—å . –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –±—ã–≤–∞–µ–º –≤ —Ä–æ—Å—Å–∏–∏', '–∫—Ä—É—Ç–æ . —è –±—ã —Ç–æ–∂–µ –ø–æ–µ—Ö–∞–ª . –∫–æ–≥–¥–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–∑ –±—ã–ª –≤ —Ä–æ—Å—Å–∏–∏ ?', '–ª–µ—Ç–æ–º  . –¥–∞–≤–Ω–æ . —Å–∫—É—á–∞—é –ø–æ —Ä–æ—Å—Å–∏–∏ . —Ç—ã –∏–∑ –∫–∞–∫–æ–≥–æ –≥–æ—Ä–æ–¥–∞', '—è –∏–∑ —Ç—É–ª—ã .', '—á–µ–º —É–≤–ª–µ–∫–∞–µ—à—å—Å—è ?', '–ª—é–±–ª—é –ª—ã–∂–∏ . –∞ —Ç—ã —á–µ–º —É–≤–ª–µ–∫–∞–µ—à—å—Å—è ?', '—è —Ç–æ–∂–µ', '–∞ —Ç—ã —á–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è , –µ—Å–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—à—å ?', '–ª–æ—à–∞–¥–µ–π –ª—é–±–ª—é , —É –Ω–∞—Å –±—ã–ª–∏ –¥–∞–≤–Ω–æ ,  –ª–æ—à–∞–¥–µ–π . –≤–æ—Ç —Å–ª–µ–¥–∏–ª –∑–∞ –Ω–∏–º–∏ ,–æ—Ç—Ü—É –ø–æ–º–æ–≥–∞–ª . —Å —Ç–µ—Ö –ø–æ—Ä —Ç–∞–∫ , –ø–æ–¥—Ä–∞–±–∞—Ç—ã–≤–∞—é –∏–Ω–æ–≥–¥–∞', '–∫–∞–∫ —Å —Ç—Ä—É–¥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ–º –≤ –Ω–æ—Ä–≤–µ–≥–∏–∏ ?', '–Ω–æ—Ä–º–∞–ª—å–Ω–æ . –±–µ–∑—Ä–∞–±–æ—Ç–Ω—ã—Ö –Ω–µ –æ—á–µ–Ω—å –º–Ω–æ–≥–æ . –¥—É–º–∞—é —ç—Ç–æ –æ—Ç –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏ .', '–ª—é–±–ª—é –ø—É—Ç–µ—à–µ—Å—Ç–≤–æ–≤–∞—Ç—å , –¥—É–º–∞—é –ø–æ—Å–µ—Ç–∏—Ç—å —Å—Ç—Ä–∞–Ω—É']\n",
      "['–ø—Ä–∏–≤–µ—Ç', '–ø—Ä–∏–≤–µ—Ç ! –∫–∞–∫ –¥–µ–ª–∞ .', '–æ–π , —Å–ª—É—à–∞–π , –¥–æ–≤–æ–ª—å–Ω–æ —Ç–∞–∫–∏ –Ω–µ–ø–ª–æ—Ö–æ . –≥–æ—Ä–∞–∑–¥–æ –ª—É—á—à–µ , —á–µ–º –¥–Ω—ë–º . –∞ —Ç–≤–æ–∏ –∫–∞–∫ ?', '–¥–∞ —Ç–æ–∂–µ –Ω–µ–ø–ª–æ—Ö–æ . –≤–æ—Ç —Ç–æ–ª—å–∫–æ —Å —Ä—ã–±–∞–ª–∫–∏ –≤–µ—Ä–Ω—É–ª—Å—è ! –ª—é–±–ª—é —ç—Ç–æ –¥–µ–ª–æ , —Ä–∞—Å—Å–ª–∞–±–ª—è–µ—Ç –∏ –ø–æ–º–æ–≥–∞–µ—Ç –æ—Ç–≤–ª–µ—á—å—Å—è –æ—Ç –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π —Ä—É—Ç–∏–Ω—ã . –∞ —Ç—ã —á–µ–º –ª—é–±–∏—à—å –∑–∞–Ω–∏–º–∞—Ç—å—Å—è –≤ —Å–≤–æ–±–æ–¥–Ω–æ–µ –≤—Ä–µ–º—è ?', '–≤ —Å–≤–æ–±–æ–¥–Ω–æ–µ –æ—Ç —Ä–∞–±–æ—Ç—ã –≤—Ä–µ–º—è —è –ª—é–±–ª—é –≥–æ—Ç–æ–≤–∏—Ç—å—Å—è –≤—Å—è–∫–∏–µ –≤–∫—É—Å–Ω–æ—Å—Ç–∏ . –≤ –¥–µ—Ç—Å—Ç–≤–µ –º–∞–º–∞ –º–µ–Ω—è —É—á–∏–ª–∞ –≥–æ—Ç–æ–≤–∏—Ç—å , –∏ —Ç–µ–º —Å–∞–º—ã–º —è –ø–æ–ª—é–±–∏–ª–∞ —ç—Ç–æ –¥–µ–ª–æ . –∞ —Å–∞–º–æ–µ —É–¥–æ–±–Ω–æ–µ –≤ —Ç–æ–º , —á—Ç–æ —Ç—ã —Ö–æ—Ä–æ—à–æ –≥–æ—Ç–æ–≤–∏—à—å , —ç—Ç–æ —Ç–æ , —á—Ç–æ —è –æ—á–µ–Ω—å –ª—é–±–ª—é —Å–ª–æ–∂–Ω–æ–µ –∏ –º–æ–≥—É –≤–∑—è—Ç—å –∏ , –Ω–∞–ø—Ä–∏–º–µ—Ä , –∏—Å–ø–µ—á—å —Å–µ–±–µ —á—Ç–æ - –Ω–∏–±—É–¥—å . . –≤ —Å–≤–æ–±–æ–¥–Ω–æ–µ –æ—Ç —Ä–∞–±–æ—Ç—ã –≤—Ä–µ–º—è —è –ª—é–±–ª—é –≥–æ—Ç–æ–≤–∏—Ç—å –≤—Å—è–∫–∏–µ –≤–∫—É—Å–Ω–æ—Å—Ç–∏ . –≤ –¥–µ—Ç—Å—Ç–≤–µ –º–∞–º–∞ –º–µ–Ω—è —É—á–∏–ª–∞ –≥–æ—Ç–æ–≤–∏—Ç—å , –∏ —Ç–µ–º —Å–∞–º—ã–º —è –ø–æ–ª—é–±–∏–ª–∞ —ç—Ç–æ –¥–µ–ª–æ . –∞ —Å–∞–º–æ–µ —É–¥–æ–±–Ω–æ–µ –≤ —Ç–æ–º , —á—Ç–æ —Ç—ã —Ö–æ—Ä–æ—à–æ –≥–æ—Ç–æ–≤–∏—à—å , —ç—Ç–æ —Ç–æ , —á—Ç–æ —è –æ—á–µ–Ω—å –ª—é–±–ª—é —Å–ª–æ–∂–Ω–æ–µ –∏ –º–æ–≥—É –≤–∑—è—Ç—å –∏ , –Ω–∞–ø—Ä–∏–º–µ—Ä , –∏—Å–ø–µ—á—å —Å–µ–±–µ —á—Ç–æ - –Ω–∏–±—É–¥—å . . –≤ —Å–≤–æ–±–æ–¥–Ω–æ–µ –æ—Ç —Ä–∞–±–æ—Ç—ã –≤—Ä–µ–º—è —è –ª—é–±–ª—é –≥–æ—Ç–æ–≤–∏—Ç—å –≤—Å—è–∫–∏–µ –≤–∫—É—Å–Ω–æ—Å—Ç–∏ . –≤ –¥–µ—Ç—Å—Ç–≤–µ –º–∞–º–∞ –º–µ–Ω—è —É—á–∏–ª–∞ –≥–æ—Ç–æ–≤–∏—Ç—å , –∏ —Ç–µ–º —Å–∞–º—ã–º —è –ø–æ–ª—é–±–∏–ª–∞ —ç—Ç–æ –¥–µ–ª–æ . –∞ —Å–∞–º–æ–µ —É–¥–æ–±–Ω–æ–µ –≤ —Ç–æ–º , —á—Ç–æ —Ç—ã —Ö–æ—Ä–æ—à–æ –≥–æ—Ç–æ–≤–∏—à—å , —ç—Ç–æ —Ç–æ , —á—Ç–æ —è –æ—á–µ–Ω—å –ª—é–±–ª—é —Å–ª–∞–¥–∫–æ–µ –∏ –º–æ–≥—É –≤–∑—è—Ç—å –∏ , –Ω–∞–ø—Ä–∏–º–µ—Ä , –∏—Å–ø–µ—á—å —Å–µ–±–µ —á—Ç–æ - –Ω–∏–±—É–¥—å . . –∞ —á—Ç–æ —Ç—ã –ª—é–±–∏—à—å –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ –∏–∑ –µ–¥—ã . –∏ –¥–∞ , —Ä—ã–±–∞–ª–∫–∞ —ç—Ç–æ —Ç–æ–∂–µ –æ—Ñ–∏–≥–µ–Ω–Ω–æ . –æ—Å–æ–±–µ–Ω–Ω–æ –Ω–µ —Å –±–µ—Ä–µ–≥–∞ , –∞ –Ω–∞ –ª–æ–¥–æ—á–∫–µ . —É—Ö . –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ', '—É—Ö —Ç—ã ! –≥–æ—Ç–æ–≤–∫–∞ - —ç—Ç–æ –∑–¥–æ—Ä–æ–≤–æ ! —è –≤–æ—Ç –≤ —ç—Ç–æ–º –Ω–µ –æ—Å–æ–±–æ —Å–∏–ª—ë–Ω . –∂–µ–Ω–∞ –≤—Å–µ–≥–¥–∞ —É –Ω–∞—Å –≥–ª–∞–≤–Ω–æ–π –ø–æ –∫—É—Ö–Ω–µ –±—ã–ª–∞ , –¥–æ—á–∫—É –¥–∞–∂–µ —É—á–∏–ª–∞ –ø–æ—Ç–∏—Ö–æ–Ω—å–∫—É . –Ω–æ –≤ –ø—Ä–æ—à–ª–æ–º –≥–æ–¥—É –µ—ë , –∫ –Ω–µ—Å—á–∞—Å—Ç—å—é , –Ω–µ —Å—Ç–∞–ª–æ . —Ç–µ–ø–µ—Ä—å –≤–æ—Ç —Å –¥–æ—á–∫–æ–π –≤–¥–≤–æ—ë–º –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –ø—ã—Ç–∞–µ–º—Å—è —á—Ç–æ - —Ç–æ –∫–æ—à–µ–≤–∞—Ä–∏—Ç—å , –Ω–æ —Ç–∞–∫ –≤–∫—É—Å–Ω–æ , –∫–∞–∫ —É –Ω–µ—ë , –∫–æ–Ω–µ—á–Ω–æ , –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è . —É –Ω–∞—Å –ª—é–±–∏–º–æ–µ –±–ª—é–¥–æ –±—ã–ª–æ –ø–∞—Å—Ç–∞ —Å –∫—Ä–µ–≤–µ—Ç–∫–∞–º–∏ . –º–æ–∂–Ω–æ —Å–∫–∞–∑–∞—Ç—å , —Ñ–∏—Ä–º–µ–Ω–Ω–æ–µ .', '–æ—Ö , —Å–æ–±–æ–ª–µ–∑–Ω—É—é .', '–Ω–∞ —Ä–∞–±–æ—Ç–µ –ø—Ä–∞–≤–¥–∞ –ø–∞—Ä–Ω–∏ –±—É—Ä–∂—É–µ–º –≤—Å–µ–≥–¥–∞ –∑–≤–∞–ª–∏ –∑–∞ —ç—Ç–æ . –≥–æ–≤–æ—Ä–∏–ª–∏ —Ç–∏–ø–∞ –∞–≤—Ç–æ—Å–ª–µ—Å–∞—Ä—é —Ç–æ –≥–æ–∂–µ –∫–∞—Ä—Ç–æ—à–∫—É –∂–∞—Ä–µ–Ω—É—é –µ—Å—Ç—å , –∞ –Ω–µ –ø–∞—Å—Ç—É . . —Å–ø–∞—Å–∏–±–æ üôèüèª . –∞ —Ç—ã –º—É–∑—ã–∫—É –ª—é–±–∏—à—å ? –∏–≥—Ä–∞–µ—à—å –Ω–∞ —á—ë–º - –Ω–∏–±—É–¥—å –º–æ–∂–µ—Ç –±—ã—Ç—å .', '—è –≤–æ—Ç –Ω–µ –∑–∞–º—É–∂–µ–º , –∏ –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –±—ã–ª–∞ . –∂–∏–≤—É —Å–æ —Å–≤–æ–∏–º–∏ –ª—é–±–∏–º—ã–º–∏ —Å–æ–±–∞—á–∫–∞–º–∏ . –æ–±–æ–∂–∞—é –ø—Ä–æ—Å—Ç–æ —Å–æ–±–∞–∫ , –æ–Ω–∏ –æ—Ñ–∏–≥–µ–Ω–Ω—ã–µ . –≤–æ—Ç —Ç—ã –ª—é–±–∏—à—å —Å–æ–±–∞–∫ ? –∏–ª–∏ –º–æ–∂–µ—Ç –¥—Ä—É–≥–∏—Ö –∫–∞–∫–∏—Ö –∂–∏–≤–æ—Ç–Ω—ã—Ö . –Ω–µ—Ç , —è –Ω–∏ –Ω–∞ —á—ë–º –Ω–µ –∏–≥—Ä–∞—é . –Ω–µ–∫–æ–≥–¥–∞ . —è –∂ —Ä–∞–±–æ—Ç–∞—é , –≤—Ä–∞—á —è , –∂–∏–∑–Ω–∏ —Å–ø–∞—Å–∞—é .', '—è —Å–æ–±–∞–∫ —Ç–æ–∂–µ –æ—á–µ–Ω—å –ª—é–±–ª—é , –∞ –≤–æ—Ç –¥–æ—á–∫–∞ –≤—Å–µ –∫–æ—Ç—ë–Ω–∫–∞ –≤—ã–ø—Ä–∞—à–∏–≤–∞–µ—Ç .', '—Å–∫–æ–ª—å–∫–æ –¥–æ—á–∫–µ –ª–µ—Ç . –≤–æ–æ–±—â–µ , —ç—Ç–æ –≥—Ä–µ—Ö . –ø—Ä–∏–æ–±—Ä–µ—Ç–∏ –¥–ª—è –Ω–µ–µ –∫–æ—Ç–µ–Ω–∫–∞ . —ç—Ç–æ –∂ –∑–¥–æ—Ä–æ–≤–æ . –∏ —â–µ–Ω–æ—á–∫–∞ –º–æ–∂–Ω–æ –µ—â—ë ; .', '–æ , —ç—Ç–æ –æ—á–µ–Ω—å –∑–¥–æ—Ä–æ–≤–æ . –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –æ—á–µ–Ω—å . –∞ —è –≤–æ—Ç –Ω–∞ –≥–∏—Ç–∞—Ä–µ –ª—é–±–ª—é –ø–æ–∏–≥—Ä–∞—Ç—å , –∫–æ–≥–¥–∞ —Å–≤–æ–±–æ–¥–Ω–∞—è –º–∏–Ω—É—Ç–∫–∞ –≤—ã–¥–∞—ë—Ç—Å—è . —Å–∞–º–æ—É—á–∫–∞ , –∫–æ–Ω–µ—á–Ω–æ , –Ω–æ —á—Ç–æ - —Ç–æ –≤—Ä–æ–¥–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è .  –≤–æ—Ç –±—É–¥–µ—Ç –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–π –Ω–µ–¥–µ–ª–µ . –¥—É–º–∞—é , –∏ –ø—Ä–∞–≤–¥–∞ –Ω–∞ –¥–µ–Ω—å —Ä–æ–∂–¥–µ–Ω–∏—è –ø–æ—Ä–∞–¥–æ–≤–∞—Ç—å –µ–µ –ø—É—à–∏—Å—Ç—ã–º –ø–æ–¥–∞—Ä–∫–æ–º . —É–∂ –æ—á–µ–Ω—å –ø—Ä–æ—Å–∏—Ç .', '–Ω—É , —É –º–µ–Ω—è –¥—Ä—É–≥ –∏–≥—Ä–∞–µ—Ç , —Ç–æ–∂–µ —Å–∞–º–æ—É—á–∫–∞ , –Ω–æ –∫–∞–∞–∞–∫ –æ–Ω –∏–≥—Ä–∞–µ—Ç .üòçüòçüòç . –¥–∞–∞–∞ , –ø–æ–¥–∞—Ä–∏ , –æ–Ω–∞ –±—É–¥–µ—Ç –æ—á–µ–Ω—å —Å—á–∞—Å—Ç–ª–∏–≤–∞ .', '—Å–ø–∞—Å–∏–±–æ –∑–∞ —Å–æ–≤–µ—Ç . –¥—É–º–∞—é , –≤–æ—Å–ø–æ–ª—å–∑—É—é—Å—å –∏–º üëçüèªüôÇ', '–ª–∞–¥–Ω–æ , –¥–æ–±—Ä–æ–π –Ω–æ—á–∏ . —Å–ø–∞—Å–∏–±–æ –∑–∞ –∫–æ–º–ø–∞–Ω–∏—é']\n",
      "['–ø—Ä–∏–≤–µ—Ç .', '–∑–¥—Ä–æ—Ä–≤–æ ! —Ç—ã –≥–¥–µ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∞–ª—å–Ω–æ ?', '—É–∫—Ä–∞–∏–Ω–∞', '–æ–≥–æ–≥–æ . —è —Ç–æ–∂–µ –∑–∞ –≥—Ä–∞–Ω–∏—Ü–µ–π . –≤ –∞–≤—Å—Ç—Ä–∏–ª–∏–∏ –∂–∏–≤—É . –∫–∞–∫–∏–µ —É–≤–ª–µ—á–µ–Ω–∏—è ?', '–ø–æ–Ω—è–ª–∞ –Ω–æ —è –¥–æ–º—Ä–∞–±–æ—Ç–Ω–∏—Ü–∞ —Ä–µ–¥–∫–æ –≥–¥–µ –±—ã–≤–∞—é . –ª—é–±–ª—é –≤–∞—Ä–∏—Ç—å –∫–æ—Ñ–µ . –∏ –ø–∏—Ç—å . —Ä–∞—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ', '–æ–≥–æ , –∫—Ä—É—Ç–æ . –¥–æ–º—Ä–∞–±–æ—Ç–Ω–∏—Ü–µ–π , –Ω–∞–≤–µ—Ä–Ω–æ–µ , —Ç—è–∂–µ–ª–æ —Ä–∞–±–æ—Ç–∞—Ç—å . –≤–æ—Ç —É –º–µ–Ω—è –ª–µ–≥–∫–æ –≤—Å–µ . —Ä–∞–±–æ—Ç–∞—é –≤ —Å–∞–¥—É —Ç–æ–ª—å–∫–æ . —É–≤–ª–µ–∫–∞—é—Å—å –±–æ—Ç–∞–Ω–∏–∫–æ–π . —Å–∞–∂–∞—é —Ä–∞–∑–Ω—ã–µ –≤–∏–¥—ã –¥–µ—Ä–µ–≤—å–µ–≤ . –∞ —Ç—ã –ª—é–±–∏—à—å —Ä–∞—Å—Ç–µ–Ω–∏—è ?', '–¥–∞ –ª—é–±–ª—é ,–∞ —Ç–∞–∫–∂–µ —Å–≤–æ—é —Å–µ–º—é –Ω–æ —è –±–µ–∑–¥–µ—Ç–Ω–∞', '–∫—Å—Ç–∞—Ç–∏ , –≤—ã–≤–æ–∂—É –Ω–æ–≤—ã–µ —Å–æ—Ä—Ç–∞ . –≤–æ—Ç —É–∂–µ —Å–µ–º—å –Ω–æ–≤—ã—Ö —Å–æ—Ä—Ç–æ–≤ —è–ª–æ–Ω—å –ø–æ—Å–∞–¥–∏–ª–∞ . –Ω—É , –¥—É–º–∞—é , —á—Ç–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –º–µ–¥–∏—Ü–∏–Ω–∞ —Ä–µ–∞—à–µ—Ç –ø–æ—á—Ç–∏ –≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã . —Ç—ã –∑–∞–º—É–∂–µ–º ?']\n",
      "['–ø—Ä–∏–≤–µ—Ç –∏–∑ –Ω–æ—Ä–≤–µ–≥–∏–∏ !', '–ø—Ä–∏–≤–µ—Ç–∏–∫ , –Ω–∏—á–µ–≥–æ —Å–µ–±–µ . . —Ç–∞–º —è –µ—â—ë –Ω–µ –±—ã–ª–∞', '—É –Ω–∞—Å –æ—á–µ–Ω—å –∫—Ä–∞—Å–∏–≤–æ , –º–æ–π –ø–æ–ø—É–≥–∞–π –≤—Å–µ–≥–¥–∞ –≥–æ–≤–æ—Ä–∏—Ç : –∫—Ä–∞—Å–æ—Ç–∞–∞–∞–∞ . . —É –≤–∞—Å –µ—Å—Ç—å –∂–∏–≤–æ—Ç–Ω—ã–µ ?', '–∞—Ö–∞—Ö . –∞ –¥–µ–≤—É—à–∫–∞–º –æ–Ω —Ç–∞–∫–æ–µ –≥–æ–≤–æ—Ä–∏—Ç –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ . —è* —Å–∫—Ä–æ–º–Ω–æ* —Å—á–∏—Ç–∞—é —Å–µ–±—è –¥–æ–≤–æ–ª—å–Ω–æ –∫—Ä–∞—Å–∏–≤–æ–π . . —É –º–µ–Ω—è –±—ã–ª–∞ —Å–æ–±–∞—á–∫–∞ –ø—É–≥–æ–≤–∫–∞ . —Å–µ–π—á–∞—Å —è –Ω–µ –≥–æ—Ç–æ–≤–∞ –Ω–æ–≤–æ–≥–æ –ø–∏—Ç–æ–º—Ü–∞ –∑–∞–≤–µ—Å—Ç–∏ .', '—Å –¥–µ—Ç—Å—Ç–≤–∞ –Ω–µ –ª—é–±–ª—é –¥–µ—Ä–µ–≤—å—è , —è —Å –Ω–∏—Ö —á–∞—Å—Ç–æ –ø–∞–¥–∞–ª , –ø–æ—ç—Ç–æ–º—É –ø–æ—Å–ª–µ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞ , —è –≤—ã—Ä—É–±–∏–ª –±–æ–ª—å—à—É—é –ø–æ–ª—è–Ω—É –≤–æ–∑–ª—è –¥–æ–º–∞ –∏ –∑–∞–≤–µ–ª –¥–µ—Å—è—Ç—å –ª–æ—à–∞–¥–µ–π . –∫—Å—Ç–∞—Ç–∏ , —Ç–æ–≥–¥–∞ —è –±—Ä–æ—Å–∏–ª –∫—É—Ä–∏—Ç—å , —á—Ç–æ–± –ª–æ—à–∞–¥–∏ –Ω–µ –ø–æ—Å—Ç—Ä–∞–¥–∞–ª–∏ . . —É –≤–∞—Å –µ—Å—Ç—å –ø–∏—Ç–æ–º—Ü—ã ?', '–∫–ª–∞—Å—Å , –æ–±–æ–∂–∞—é –∂–∏–≤–æ—Ç–Ω—ã—Ö . —Ç—ã –∂–∏–≤—ë—à—å –≤ —á–∞—Å—Ç–Ω–æ–º –¥–æ–º–µ ? —è –≤ –º–Ω–æ–≥–æ—ç—Ç–∞–∂–∫–µ –Ω–∞ –ø–µ—Ä–≤–æ–º , —Ç–∞–∫ —á—Ç–æ –Ω–∏–∫–∞–∫–æ–π –ø–æ–ª—è–Ω—ã —Å–≤–æ–µ–π . –∑–¥–æ—Ä–æ–≤–æ , —á—Ç–æ —Ç—ã –æ –Ω–∏—Ö –∑–∞–±–æ—Ç–∏—à—å—Å—è . –∞ —É —Ç–µ–±—è –µ—Å—Ç—å –±–µ–ª—ã–µ –ª–æ—à–∞–¥–∏ ?', '—É–∂–µ –Ω–µ—Ç –Ω–∏–∫–∞–∫–∏—Ö , –ø—Ä–∏—à–ª–æ—Å—å –≤—ã–≤–µ—Å—Ç–∏ –∏—Ö . . —á–µ–º —É–≤–ª–µ–∫–∞–µ—Ç–µ—Å—å ?', '—á—Ç–æ–æ–æ . –∞ —è –º–µ—á—Ç–∞–ª–∞ –æ –±–µ–ª–æ–π –ª–æ—à–∞–¥–∏ —Å –±–µ–ª–æ–π –≥—Ä–∏–≤–æ–π , —è –±—ã –æ—Ñ–∏–≥–µ–Ω–Ω–æ –Ω–∞ –Ω–µ–π —Å–º–æ—Ç—Ä–µ–ª–∞—Å—å , —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥—Å—Ç–∞–≤—å –∫—Ä–∞—Å–∏–≤–∞—è –±–ª–æ–Ω–¥–∏–Ω–∫–∞ —Å –æ—Ç–ª–∏—á–Ω–æ–π —Ñ–∏–≥—É—Ä–æ–π . . —è –∫—Å—Ç–∞—Ç–∏ –Ω–µ –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏—è—Ö . —É–≤–ª–µ–∫–∞—é—Å—å –Ω—É—É –ª—é–±–ª—é —á–∏—Ç–∞—Ç—å –≥–ª—è–Ω–µ—Ü , –∞ —Ç–∞–∫ —É—á—ë–±–∞ –≤—Å–µ . –∞ —Ç—ã ?', '—è –∫–Ω–∏–≥–∏ –ª—é–±–ª—é . –∏–∑–≤–∏–Ω–∏—Ç–µ –ø–æ—Ä–∞ –±–µ–∂–∞—Ç—å , –¥–æ—á—å –∏–∑ —Å–∞–¥–∞ –∑–∞–±–∏—Ä–∞—Ç—å']\n"
     ]
    }
   ],
   "source": [
    "for i in data['dialogue_list'].head(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T16:33:48.938198Z",
     "start_time": "2019-12-01T16:33:48.546080Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "YXKXBkJtmE76"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T16:33:49.094086Z",
     "start_time": "2019-12-01T16:33:48.940601Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "xsiDp1nimE7-",
    "outputId": "890ff673-2983-4fd2-81aa-60ac3dfbcb7a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(l.split(' ')) for l in sum(data['dialogue_list'].tolist(),[])], bins=100)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "SiJEXFoHUNr5",
    "outputId": "578af0d1-027b-4166-c80d-3e389fd57cbb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(l) for l in data['dialogue_list'].tolist()], bins=100)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9nXrsihvUjBE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T16:33:49.106131Z",
     "start_time": "2019-12-01T16:33:49.096232Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "m6eHX9DcmE8B"
   },
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "    def __init__(self, tokens, min_freq=0, use_special_tokens=False):\n",
    "        counter = collections.Counter(tokens)\n",
    "        self.token_freqs = sorted(counter.items(), key=lambda x: x[0])\n",
    "        self.token_freqs.sort(key=lambda x: x[1], reverse=True)\n",
    "        if use_special_tokens:\n",
    "            self.pad, self.bos, self.eos, self.unk = (0, 1, 2, 3)\n",
    "            uniq_tokens = ['<pad>', '<bos>', '<eos>', '<unk>']\n",
    "        else:\n",
    "            self.unk, uniq_tokens = 0, ['<unk>']\n",
    "        uniq_tokens +=  [token for token, freq in self.token_freqs \n",
    "                         if freq >= min_freq and token not in uniq_tokens]\n",
    "        self.idx_to_token, self.token_to_idx = [], dict()\n",
    "        for token in uniq_tokens:\n",
    "            self.idx_to_token.append(token)\n",
    "            self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nmkyPk6oUTKd"
   },
   "outputs": [],
   "source": [
    "source = [[s.split(' ') for s in l] for l in data['dialogue_list'].tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3HShTv-Z60Y2",
    "outputId": "ab567366-a1e2-4fea-a768-5179440503fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10013"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4lAC69BTp9VF"
   },
   "outputs": [],
   "source": [
    "tmp_sourse = sum(source, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BUM3IwRdtSUo"
   },
   "outputs": [],
   "source": [
    "tmp2_sourse = sum(tmp_sourse, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eHkJ3EhP7tpQ",
    "outputId": "f737d83b-debe-4835-b9c4-a9652fac07e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62563"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tmp2_sourse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZmReBnFS-ou0"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yhrXYG5k91nh"
   },
   "outputs": [],
   "source": [
    "with open('./drive/My Drive/data_for_hw_9.pkl', 'wb') as f:\n",
    "    pickle.dump(tmp2_sourse, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ax0wdYU1-mnc"
   },
   "outputs": [],
   "source": [
    "#with open('./drive/My Drive/data_for_hw_9.pkl', 'rb') as f:\n",
    "with open('data_for_hw_9.pkl', 'rb') as f:\n",
    "    tmp2_sourse = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T16:33:49.114035Z",
     "start_time": "2019-12-01T16:33:49.108556Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CfGDDF-1mE8E",
    "outputId": "e5eb9fa8-d45d-4321-b5e7-2aa89403bbee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19439"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_vocab(tokens):\n",
    "    #tokens = [token for line in tokens for token in line]\n",
    "    return Vocab(tokens, min_freq=3, use_special_tokens=True)\n",
    "\n",
    "src_vocab = build_vocab(tmp2_sourse)\n",
    "len(src_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "wXwXFEnoU2pn",
    "outputId": "fc813990-e911-418c-dd51-6a0492e4f94b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[18, 4, 148, 38, 68],\n",
       " [18, 4, 287, 1384, 11989, 236, 737, 3817, 4],\n",
       " [23, 1439, 7, 31, 85, 2476, 4, 6, 29, 14, 189],\n",
       " [14, 79, 5, 93, 74, 5, 17, 11, 145, 151, 4, 6, 1260, 14],\n",
       " [8, 6, 1197, 3512, 4, 11, 802, 861, 11, 653, 655, 119, 22],\n",
       " [318, 13, 5, 152, 4],\n",
       " [13, 1073, 12, 7681, 15, 6406, 6519, 7, 6, 136, 21, 448, 4]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab[source[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T16:33:49.122605Z",
     "start_time": "2019-12-01T16:33:49.116449Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "colab_type": "code",
    "id": "PEjNcRCEmE8J",
    "outputId": "99351d62-0b9c-46dc-8d4e-a4f9dfd432f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18,\n",
       " 4,\n",
       " 148,\n",
       " 38,\n",
       " 68,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pad(line, max_len, padding_token):\n",
    "    if len(line) > max_len:\n",
    "        return line[:max_len]\n",
    "    return line + [padding_token] * (max_len - len(line))\n",
    "\n",
    "pad(src_vocab[source[0][0]], 50, src_vocab.pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ujVpFBfnVp_D"
   },
   "outputs": [],
   "source": [
    "def pad_line(lines, max_len_line, padding_token):\n",
    "    if len(lines) > max_len_line:\n",
    "        return lines[:max_len_line]\n",
    "    return lines + [padding_token] * (max_len_line - len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T16:33:49.131148Z",
     "start_time": "2019-12-01T16:33:49.125106Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3NB9uSA-mE8M"
   },
   "outputs": [],
   "source": [
    "def build_array(lines, vocab, max_len, max_len_line):\n",
    "    lines = [vocab[line] for line in lines]\n",
    "    lines = [[pad([vocab.bos] + l + [vocab.eos],max_len,vocab.pad) for l in line] for line in lines]\n",
    "    lines = [pad_line(line,max_len_line,[vocab.pad]*max_len) for line in lines]\n",
    "    array = torch.LongTensor(lines)\n",
    "    valid_len = (array != vocab.pad).sum(axis=2)\n",
    "    mask = torch.zeros_like(array).type(torch.float)\n",
    "    mask = (array != vocab.pad).type(torch.float)\n",
    "    #for i in range(len(valid_len)):\n",
    "    #    mask[i, :valid_len[i]]=1.\n",
    "    return array, valid_len, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T16:33:49.138015Z",
     "start_time": "2019-12-01T16:33:49.133576Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "0GknL2yqmE8P"
   },
   "outputs": [],
   "source": [
    "def load_data_nmt(batch_size, max_len, max_len_lines): \n",
    "    src_vocab = build_vocab(tmp2_sourse)\n",
    "    src_array, src_valid_len, src_trg = build_array(source[:1000], src_vocab, max_len, max_len_lines)\n",
    "    train_data = torch.utils.data.TensorDataset(src_array, src_valid_len, src_trg)\n",
    "    train_iter = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True)\n",
    "    return src_vocab, train_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T16:33:49.182063Z",
     "start_time": "2019-12-01T16:33:49.175703Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "hdKCPxyimE8U"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.LSTM(embed_size, num_hiddens, num_layers, dropout=dropout)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.set_state = None\n",
    "\n",
    "    def forward(self, X, is_set_state, *args):\n",
    "        X = self.embedding(X) \n",
    "        X = X.permute(1, 0, 2)\n",
    "        if is_set_state and (self.set_state is not None): \n",
    "            \n",
    "            state = (self.set_state[0].detach(),self.set_state[1].detach())\n",
    "        else:\n",
    "            \n",
    "            state = (torch.zeros((self.num_layers, X.shape[1],self.num_hiddens)), torch.zeros((self.num_layers, X.shape[1],self.num_hiddens)))\n",
    "        out, self.set_state = self.rnn(X, state)\n",
    "        \n",
    "        return out, self.set_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T19:16:43.077500Z",
     "start_time": "2019-12-01T19:16:43.070765Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "e8j-NI44mE8_"
   },
   "outputs": [],
   "source": [
    "class MLPAttention(nn.Module):  \n",
    "    def __init__(self, inputs, units, dropout, **kwargs):\n",
    "        super(MLPAttention, self).__init__(**kwargs)\n",
    "        self.W_k = nn.Linear(inputs, units, bias=False)\n",
    "        self.W_q = nn.Linear(inputs, units, bias=False)\n",
    "        self.v = nn.Linear(units, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        query, key = torch.tanh(self.W_k(query)), torch.tanh(self.W_q(key))\n",
    "        # expand query to (batch_size, #querys, 1, units), and key to \n",
    "        # (batch_size, 1, #kv_pairs, units). Then plus them with broadcast.  \n",
    "        features = query.unsqueeze(2) + key.unsqueeze(1)\n",
    "        scores = self.v(features).squeeze(dim=-1)\n",
    "        attention_weights = self.dropout(scores.softmax(dim=-1))\n",
    "        return torch.bmm(attention_weights, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T19:17:55.737695Z",
     "start_time": "2019-12-01T19:17:55.726847Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "dSMDfrKYmE9F"
   },
   "outputs": [],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention_cell = MLPAttention(num_hiddens, num_hiddens, dropout)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.LSTM(embed_size + num_hiddens, num_hiddens, num_layers, dropout=dropout)\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embed_size = embed_size\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        return (enc_outputs[0].permute(1,0,2), enc_outputs[1])\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        enc_outputs, hidden_state = state\n",
    "        X = self.embedding(X).permute(1, 0, 2)\n",
    "        outputs = []\n",
    "        for x in X:\n",
    "            # query shape: (batch_size, 1, hidden_size)\n",
    "            query = hidden_state[0][-1].unsqueeze(1)\n",
    "            # context has same shape as query\n",
    "            context = self.attention_cell(query, enc_outputs, enc_outputs)\n",
    "            # concatenate on the feature dimension\n",
    "            x = torch.cat([context, x.unsqueeze(1)], dim=-1)\n",
    "            # reshape x to (1, batch_size, embed_size+hidden_size)\n",
    "            out, hidden_state = self.rnn(x.permute(1, 0, 2), hidden_state)\n",
    "            outputs.append(out)\n",
    "        outputs = self.dense(torch.cat(outputs, dim=0))\n",
    "        return outputs.permute(1, 0, 2), [enc_outputs, hidden_state]\n",
    "            \n",
    "            \n",
    "       # out, state = self.rnn(X, state)\n",
    "       # out = self.dense(out.view(-1, self.num_hiddens)).view(out.shape[0], out.shape[1], self.vocab_size).permute(1, 0, 2)\n",
    "       # return out, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_X, dec_X, is_set_state, *args):\n",
    "        enc_outputs = self.encoder(enc_X, is_set_state, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T16:33:49.391439Z",
     "start_time": "2019-12-01T16:33:49.383164Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ru_v9db3mE8m"
   },
   "outputs": [],
   "source": [
    "def train(model, data_iter, lr, num_epochs, out_vocab_size,trainer=None):\n",
    "    if trainer is None:\n",
    "        trainer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss = nn.CrossEntropyLoss(reduction='none')\n",
    "    tic = time.time()\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        l_sum, num_tokens_sum , num_batch= 0.0, 0.0, 0\n",
    "        print(f'batch ', end=' ')\n",
    "        for batch in data_iter:\n",
    "            print(f' {num_batch} ', end=' ')\n",
    "            #is_set_state = False\n",
    "            X, X_vlen, mask = [x for x in batch]\n",
    "            #X, X_vlen, Y, Y_vlen, mask = [x for x in batch]\n",
    "            use_state = False\n",
    "            for i in range(X.shape[1]-1):\n",
    "                trainer.zero_grad()\n",
    "                #Y_input, Y_label, Y_vlen, mask = Y[:,:-1], Y[:,1:], Y_vlen-1, mask[:,1:]\n",
    "                #print(X.shape, X_vlen.shape, mask.shape)     \n",
    "                cur_X, cur_X_vlen, cur_Y, cur_Y_vlen, cur_mask = X[:,i,:], X_vlen[:,i], X[:,i+1,:], X_vlen[:,i+1], mask[:,i+1,:]  \n",
    "                \n",
    "                cur_Y_input, cur_Y_label, cur_Y_vlen, cur_mask = cur_Y[:,:-1], cur_Y[:,1:], cur_Y_vlen-1, cur_mask[:,1:]\n",
    "                \n",
    "                cur_Y_hat, _ = model(cur_X, cur_Y_input, use_state, cur_X_vlen, cur_Y_vlen )\n",
    "            \n",
    "                l = (loss(cur_Y_hat.reshape(-1,out_vocab_size), cur_Y_label.reshape(-1)) * cur_mask.reshape(-1)).sum() \n",
    "            \n",
    "                l.backward()\n",
    "                num_tokens = cur_Y_vlen.sum().item()\n",
    "                trainer.step()\n",
    "                l_sum += l.item()\n",
    "                num_tokens_sum += num_tokens\n",
    "                use_state = True\n",
    "            num_batch+=1 \n",
    "        print(\"epoch %d, loss %.3f, time %.1f sec\" % (\n",
    "            epoch, l_sum/num_tokens_sum, time.time()-tic))\n",
    "        tic = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T19:21:38.863638Z",
     "start_time": "2019-12-01T19:18:40.387133Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "C0AWJhXomE9L",
    "outputId": "e4cc3466-8a24-4223-b18a-fb189f4b6082",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "epoch 1, loss 7.438, time 217.6 sec\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "epoch 2, loss 6.949, time 217.0 sec\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "epoch 3, loss 6.439, time 215.9 sec\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "epoch 4, loss 6.095, time 216.2 sec\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "epoch 5, loss 5.894, time 215.4 sec\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "epoch 6, loss 5.741, time 216.8 sec\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "epoch 7, loss 5.613, time 218.4 sec\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "epoch 8, loss 5.496, time 215.9 sec\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "epoch 9, loss 5.403, time 218.8 sec\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "epoch 10, loss 5.316, time 217.1 sec\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "epoch 11, loss 5.242, time 219.4 sec\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n",
      "batch 6\n",
      "batch 7\n",
      "batch 8\n",
      "batch 9\n",
      "epoch 12, loss 5.177, time 227.2 sec\n",
      "batch 0\n",
      "batch 1\n",
      "batch 2\n",
      "batch 3\n",
      "batch 4\n",
      "batch 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-c871d610a8a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-dab1af62af3c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_iter, lr, num_epochs, out_vocab_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_Y_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_vocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_Y_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcur_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0mnum_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_Y_vlen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.0\n",
    "batch_size, max_len, max_len_lines = 100, 50, 40\n",
    "lr, num_epochs = 0.01, 75\n",
    "\n",
    "src_vocab, train_iter = load_data_nmt(batch_size=100, max_len=50, max_len_lines = 40)\n",
    "encoder = Encoder(\n",
    "    len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "decoder = AttentionDecoder(\n",
    "    len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "model = EncoderDecoder(encoder, decoder)\n",
    "train(model, train_iter, lr, num_epochs, len(src_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ju-MauE0mE9R"
   },
   "outputs": [],
   "source": [
    "def translate(model, src_sentence, src_vocab, tgt_vocab, max_len):\n",
    "    res = []\n",
    "    use_state = False\n",
    "    for sen in  src_sentence:\n",
    "        src_tokens = src_vocab[sen.lower().split(' ')]\n",
    "        src_len = len(src_tokens)\n",
    "        if src_len < max_len:\n",
    "            src_tokens += [src_vocab.pad] * (max_len - src_len)\n",
    "        enc_X = torch.LongTensor(src_tokens)\n",
    "        enc_valid_length = torch.LongTensor([src_len])\n",
    "                    \n",
    "        enc_outputs = model.encoder(enc_X.unsqueeze(axis=0),use_state, enc_valid_length )\n",
    "        use_state = True\n",
    "        dec_state = model.decoder.init_state(enc_outputs, enc_valid_length)\n",
    "        dec_X = torch.LongTensor([tgt_vocab.bos]).unsqueeze(axis=0)\n",
    "        predict_tokens = []\n",
    "        for _ in range(max_len):\n",
    "            Y, dec_state = model.decoder(dec_X, dec_state)\n",
    "            dec_X = Y.argmax(axis=2)\n",
    "            py = dec_X.squeeze(axis=0).type(torch.long).item()\n",
    "            if py == tgt_vocab.eos:\n",
    "                break\n",
    "            predict_tokens.append(py)\n",
    "        res.append(f\"{sen} =>{' '.join(tgt_vocab.to_tokens(predict_tokens))}\")\n",
    "    return res  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T19:21:48.643911Z",
     "start_time": "2019-12-01T19:21:48.615104Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "_qqd9h-8mE9P",
    "outputId": "6ba0d1e4-de51-4f33-b083-b992bb3e67cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–ü—Ä–∏–≤–µ—Ç . =>—è —Ç–æ–∂–µ –ª—é–±–ª—é .', ' –ö–∞–∫ –¥–µ–ª–∞ ? =>–∞ —è –ª—é–±–ª—é —á–∏—Ç–∞—Ç—å .'] ['–ü—Ä–∏–≤–µ—Ç . =>—è —Ç–æ–∂–µ –ª—é–±–ª—é .', '–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ? =>—è —Ç–æ–∂–µ –ª—é–±–ª—é .', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ? =>—è —Ç–æ–∂–µ –ª—é–±–ª—é .', '–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ? =>—è —Ç–æ–∂–µ –ª—é–±–ª—é .']\n"
     ]
    }
   ],
   "source": [
    "all_sent = []\n",
    "for sentence in [['–ü—Ä–∏–≤–µ—Ç .' , ' –ö–∞–∫ –¥–µ–ª–∞ ?'],['–ü—Ä–∏–≤–µ—Ç .','–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ?','–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ?']]:\n",
    "    all_sent.append( translate(model, sentence, src_vocab, src_vocab, max_len)) \n",
    "print(*all_sent)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "id": "nnP3tRXDCbbh",
    "outputId": "47082755-b098-493d-ed5e-42a325c35b9a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 1, loss 5.356, time 221.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 2, loss 5.107, time 218.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 3, loss 4.974, time 218.4 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 4, loss 4.901, time 219.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 5, loss 4.818, time 217.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 6, loss 4.753, time 218.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 7, loss 4.698, time 218.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 8, loss 4.653, time 217.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 9, loss 4.611, time 218.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 10, loss 4.571, time 220.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 11, loss 4.543, time 220.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 12, loss 4.508, time 222.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 13, loss 4.481, time 225.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 14, loss 4.454, time 226.4 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 15, loss 4.425, time 228.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 16, loss 4.918, time 226.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 17, loss 4.547, time 223.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 18, loss 4.463, time 226.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 19, loss 4.422, time 228.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 20, loss 4.394, time 229.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 21, loss 4.370, time 230.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 22, loss 4.340, time 232.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 23, loss 4.313, time 233.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 24, loss 4.294, time 238.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 25, loss 4.270, time 240.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 26, loss 4.252, time 241.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 27, loss 4.237, time 242.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 28, loss 4.223, time 244.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 29, loss 4.208, time 244.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 30, loss 4.202, time 245.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 31, loss 4.190, time 248.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 32, loss 4.218, time 248.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 33, loss 4.222, time 249.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 34, loss 4.193, time 250.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 35, loss 4.177, time 249.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 36, loss 4.194, time 247.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 37, loss 4.181, time 247.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 38, loss 4.152, time 249.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 39, loss 4.137, time 250.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 40, loss 4.123, time 250.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 41, loss 4.101, time 250.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 42, loss 4.089, time 251.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 43, loss 4.080, time 251.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 44, loss 4.091, time 252.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 45, loss 4.108, time 252.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 46, loss 4.115, time 252.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 47, loss 4.113, time 252.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 48, loss 4.096, time 252.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 49, loss 4.096, time 252.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 50, loss 4.069, time 252.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 51, loss 4.044, time 253.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 52, loss 4.035, time 253.4 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 53, loss 4.022, time 253.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 54, loss 4.008, time 253.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 55, loss 4.000, time 254.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 56, loss 3.990, time 254.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 57, loss 3.983, time 255.4 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 58, loss 3.975, time 256.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 59, loss 3.963, time 256.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 60, loss 3.956, time 255.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 61, loss 3.950, time 254.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 62, loss 3.950, time 256.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 63, loss 3.944, time 255.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 64, loss 3.936, time 255.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 65, loss 3.929, time 255.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 66, loss 3.925, time 255.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 67, loss 3.923, time 255.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 68, loss 3.914, time 255.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 69, loss 3.909, time 255.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 70, loss 3.905, time 255.4 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 71, loss 3.905, time 257.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 72, loss 3.901, time 257.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 73, loss 3.893, time 255.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 74, loss 3.891, time 256.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 75, loss 3.998, time 257.0 sec\n"
     ]
    }
   ],
   "source": [
    "train(model, train_iter, lr, num_epochs, len(src_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–ü—Ä–∏–≤–µ—Ç . =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', ' –ö–∞–∫ –¥–µ–ª–∞ ? =>–ø—Ä–∏–≤–µ—Ç . —è –∏–Ω–∂–µ–Ω–µ—Ä .'] ['–ü—Ä–∏–≤–µ—Ç . =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', '–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ? =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ? =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', '–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ? =>–∞ —è –ª—é–±–ª—é –≥–æ—Ç–æ–≤–∏—Ç—å .']\n"
     ]
    }
   ],
   "source": [
    "all_sent = []\n",
    "for sentence in [['–ü—Ä–∏–≤–µ—Ç .' , ' –ö–∞–∫ –¥–µ–ª–∞ ?'],['–ü—Ä–∏–≤–µ—Ç .','–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ?','–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ?']]:\n",
    "    all_sent.append( translate(model, sentence, src_vocab, src_vocab, max_len)) \n",
    "print(*all_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 1, loss 3.983, time 256.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 2, loss 3.897, time 256.4 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 3, loss 3.892, time 257.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 4, loss 3.885, time 256.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 5, loss 3.877, time 256.4 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 6, loss 3.877, time 256.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 7, loss 3.868, time 256.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 8, loss 3.860, time 256.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 9, loss 3.860, time 256.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 10, loss 3.855, time 256.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 11, loss 3.853, time 256.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 12, loss 3.847, time 255.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 13, loss 3.847, time 255.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 14, loss 3.839, time 255.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 15, loss 3.830, time 254.8 sec\n"
     ]
    }
   ],
   "source": [
    "train(model, train_iter, lr, num_epochs, len(src_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–ü—Ä–∏–≤–µ—Ç . =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', ' –ö–∞–∫ –¥–µ–ª–∞ ? =>—è —Ç–æ–∂–µ .'] ['–ü—Ä–∏–≤–µ—Ç . =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', '–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ? =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ? =>—è —Ç–æ–∂–µ .', '–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ? =>—è —Ç–æ–∂–µ .']\n"
     ]
    }
   ],
   "source": [
    "all_sent = []\n",
    "for sentence in [['–ü—Ä–∏–≤–µ—Ç .' , ' –ö–∞–∫ –¥–µ–ª–∞ ?'],['–ü—Ä–∏–≤–µ—Ç .','–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ?','–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ?']]:\n",
    "    all_sent.append( translate(model, sentence, src_vocab, src_vocab, max_len)) \n",
    "print(*all_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 1, loss 3.916, time 254.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 2, loss 3.855, time 255.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 3, loss 3.848, time 254.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 4, loss 3.842, time 254.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 5, loss 3.842, time 254.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 6, loss 3.834, time 254.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 7, loss 3.832, time 254.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 8, loss 3.825, time 254.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 9, loss 3.823, time 254.4 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 10, loss 3.810, time 253.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 11, loss 3.825, time 254.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 12, loss 3.816, time 253.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 13, loss 3.814, time 253.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 14, loss 3.821, time 253.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 15, loss 3.821, time 253.9 sec\n"
     ]
    }
   ],
   "source": [
    "train(model, train_iter, lr, num_epochs, len(src_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–ü—Ä–∏–≤–µ—Ç . =>–∫–∞–∫ —Ç–µ–±—è –∑–æ–≤—É—Ç ?', ' –ö–∞–∫ –¥–µ–ª–∞ ? =>–ø—Ä–∏–≤–µ—Ç !'] ['–ü—Ä–∏–≤–µ—Ç . =>–∫–∞–∫ —Ç–µ–±—è –∑–æ–≤—É—Ç ?', '–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ? =>–ø—Ä–∏–≤–µ—Ç !', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ? =>–ø—Ä–∏–≤–µ—Ç .', '–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ? =>—è —Ç–æ–∂–µ .']\n"
     ]
    }
   ],
   "source": [
    "all_sent = []\n",
    "for sentence in [['–ü—Ä–∏–≤–µ—Ç .' , ' –ö–∞–∫ –¥–µ–ª–∞ ?'],['–ü—Ä–∏–≤–µ—Ç .','–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ?','–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ?']]:\n",
    "    all_sent.append( translate(model, sentence, src_vocab, src_vocab, max_len)) \n",
    "print(*all_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 1, loss 3.896, time 254.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 2, loss 3.847, time 254.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 3, loss 3.847, time 254.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 4, loss 3.850, time 254.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 5, loss 3.847, time 253.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 6, loss 3.840, time 254.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 7, loss 3.830, time 254.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 8, loss 3.819, time 254.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 9, loss 3.812, time 253.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 10, loss 3.814, time 254.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 11, loss 3.828, time 253.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 12, loss 3.814, time 252.4 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 13, loss 3.796, time 252.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 14, loss 3.786, time 253.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 15, loss 3.790, time 253.7 sec\n"
     ]
    }
   ],
   "source": [
    "train(model, train_iter, lr, num_epochs, len(src_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–ü—Ä–∏–≤–µ—Ç . =>–∫–∞–∫ –¥–µ–ª–∞ . —è —Ç–æ–∂–µ .', ' –ö–∞–∫ –¥–µ–ª–∞ ? =>—è —Ç–æ–∂–µ –ª—é–±–ª—é . –∞ –≤—ã ?'] ['–ü—Ä–∏–≤–µ—Ç . =>–∫–∞–∫ –¥–µ–ª–∞ . —è —Ç–æ–∂–µ .', '–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ? =>–∫–∞–∫ –¥–µ–ª–∞ ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ? =>–∫–∞–∫ –¥–µ–ª–∞ ?', '–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ? =>—è —Ç–æ–∂–µ –ª—é–±–ª—é . –∞ –≤—ã ?']\n"
     ]
    }
   ],
   "source": [
    "all_sent = []\n",
    "for sentence in [['–ü—Ä–∏–≤–µ—Ç .' , ' –ö–∞–∫ –¥–µ–ª–∞ ?'],['–ü—Ä–∏–≤–µ—Ç .','–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ?','–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ?']]:\n",
    "    all_sent.append( translate(model, sentence, src_vocab, src_vocab, max_len)) \n",
    "print(*all_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 1, loss 3.838, time 253.4 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 2, loss 3.758, time 252.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 3, loss 3.727, time 253.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 4, loss 3.727, time 253.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 5, loss 3.701, time 252.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 6, loss 3.701, time 252.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 7, loss 3.687, time 252.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 8, loss 3.678, time 252.4 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 9, loss 3.675, time 251.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 10, loss 3.670, time 253.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 11, loss 3.670, time 252.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 12, loss 3.668, time 254.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 13, loss 3.657, time 254.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 14, loss 3.653, time 261.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 15, loss 3.649, time 254.2 sec\n"
     ]
    }
   ],
   "source": [
    "train(model, train_iter, lr*0.7, num_epochs, len(src_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–ü—Ä–∏–≤–µ—Ç . =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', ' –ö–∞–∫ –¥–µ–ª–∞ ? =>–ø—Ä–∏–≤–µ—Ç . —è —Ä–∞–±–æ—Ç–∞—é –≤ –∞–≤—Ç–æ—Å–µ—Ä–≤–∏—Å–µ .'] ['–ü—Ä–∏–≤–µ—Ç . =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', '–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ? =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ? =>—è —Ç–æ–∂–µ .', '–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ? =>—è —Ç–æ–∂–µ .']\n"
     ]
    }
   ],
   "source": [
    "all_sent = []\n",
    "for sentence in [['–ü—Ä–∏–≤–µ—Ç .' , ' –ö–∞–∫ –¥–µ–ª–∞ ?'],['–ü—Ä–∏–≤–µ—Ç .','–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ?','–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ?']]:\n",
    "    all_sent.append( translate(model, sentence, src_vocab, src_vocab, max_len)) \n",
    "print(*all_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 1, loss 3.704, time 250.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 2, loss 3.659, time 250.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 3, loss 3.657, time 250.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 4, loss 3.649, time 251.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 5, loss 3.646, time 248.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 6, loss 3.641, time 247.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 7, loss 3.639, time 248.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 8, loss 3.632, time 248.4 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 9, loss 3.635, time 249.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 10, loss 3.628, time 246.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 11, loss 3.622, time 244.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 12, loss 3.618, time 240.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 13, loss 3.624, time 248.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 14, loss 3.621, time 255.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 15, loss 3.621, time 253.2 sec\n"
     ]
    }
   ],
   "source": [
    "train(model, train_iter, lr*0.7, num_epochs, len(src_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–ü—Ä–∏–≤–µ—Ç . =>–∫–∞–∫ –¥–µ–ª–∞ ?', ' –ö–∞–∫ –¥–µ–ª–∞ ? =>–ø—Ä–∏–≤–µ—Ç . —è —Ä–∞–±–æ—Ç–∞—é –≤ –æ—Ñ–∏—Å–µ .'] ['–ü—Ä–∏–≤–µ—Ç . =>–∫–∞–∫ –¥–µ–ª–∞ ?', '–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ? =>–∫–∞–∫ –¥–µ–ª–∞ ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ? =>–∫–∞–∫ –¥–µ–ª–∞ ?', '–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ? =>–∞ —è –ª—é–±–ª—é –≥–æ—Ç–æ–≤–∏—Ç—å .']\n"
     ]
    }
   ],
   "source": [
    "all_sent = []\n",
    "for sentence in [['–ü—Ä–∏–≤–µ—Ç .' , ' –ö–∞–∫ –¥–µ–ª–∞ ?'],['–ü—Ä–∏–≤–µ—Ç .','–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ?','–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ?']]:\n",
    "    all_sent.append( translate(model, sentence, src_vocab, src_vocab, max_len)) \n",
    "print(*all_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 1, loss 3.825, time 242.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 2, loss 3.774, time 237.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 3, loss 3.771, time 240.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 4, loss 3.748, time 244.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 5, loss 3.708, time 238.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 6, loss 3.679, time 243.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 7, loss 3.677, time 248.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 8, loss 3.694, time 246.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 9, loss 3.670, time 247.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 10, loss 3.654, time 259.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 11, loss 3.666, time 267.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 12, loss 3.674, time 262.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 13, loss 3.657, time 251.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 14, loss 3.661, time 244.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 15, loss 3.648, time 248.1 sec\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "trainer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "train(model, train_iter, lr, num_epochs, len(src_vocab),trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–ü—Ä–∏–≤–µ—Ç . =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', ' –ö–∞–∫ –¥–µ–ª–∞ ? =>–ø—Ä–∏–≤–µ—Ç . –∞ —Ç—ã ?'] ['–ü—Ä–∏–≤–µ—Ç . =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', '–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ? =>–∫–∞–∫ –¥–µ–ª–∞ ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ? =>–∫–∞–∫ –¥–µ–ª–∞ ?', '–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ? =>—è –∫—É—Ä—å–µ—Ä .']\n"
     ]
    }
   ],
   "source": [
    "all_sent = []\n",
    "for sentence in [['–ü—Ä–∏–≤–µ—Ç .' , ' –ö–∞–∫ –¥–µ–ª–∞ ?'],['–ü—Ä–∏–≤–µ—Ç .','–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ?','–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ?']]:\n",
    "    all_sent.append( translate(model, sentence, src_vocab, src_vocab, max_len)) \n",
    "print(*all_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 1, loss 3.550, time 253.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 2, loss 3.480, time 258.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 3, loss 3.462, time 255.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 4, loss 3.451, time 253.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 5, loss 3.444, time 255.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 6, loss 3.438, time 262.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 7, loss 3.433, time 263.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 8, loss 3.429, time 263.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 9, loss 3.426, time 258.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 10, loss 3.423, time 264.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 11, loss 3.421, time 261.4 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 12, loss 3.420, time 263.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 13, loss 3.418, time 261.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 14, loss 3.417, time 261.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 15, loss 3.415, time 264.9 sec\n"
     ]
    }
   ],
   "source": [
    "lr = 0.005\n",
    "trainer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "train(model, train_iter, lr, num_epochs, len(src_vocab), trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–ü—Ä–∏–≤–µ—Ç . =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', ' –ö–∞–∫ –¥–µ–ª–∞ ? =>–ø—Ä–∏–≤–µ—Ç . –∞ —è –æ—Ö–æ—Ç–Ω–∏–∫ , –∞ —Ç—ã ?'] ['–ü—Ä–∏–≤–µ—Ç . =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', '–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ? =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ? =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', '–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ? =>—è —Ç–æ–∂–µ .']\n"
     ]
    }
   ],
   "source": [
    "all_sent = []\n",
    "for sentence in [['–ü—Ä–∏–≤–µ—Ç .' , ' –ö–∞–∫ –¥–µ–ª–∞ ?'],['–ü—Ä–∏–≤–µ—Ç .','–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ?','–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ?']]:\n",
    "    all_sent.append( translate(model, sentence, src_vocab, src_vocab, max_len)) \n",
    "print(*all_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 1, loss 3.421, time 245.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 2, loss 3.416, time 245.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 3, loss 3.414, time 246.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 4, loss 3.413, time 255.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 5, loss 3.412, time 259.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 6, loss 3.410, time 255.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 7, loss 3.409, time 253.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 8, loss 3.408, time 257.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 9, loss 3.408, time 265.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 10, loss 3.407, time 264.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 11, loss 3.407, time 259.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 12, loss 3.406, time 258.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 13, loss 3.407, time 256.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 14, loss 3.405, time 253.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 15, loss 3.405, time 258.7 sec\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "trainer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "train(model, train_iter, lr, num_epochs, len(src_vocab), trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–ü—Ä–∏–≤–µ—Ç . =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', ' –ö–∞–∫ –¥–µ–ª–∞ ? =>–ø—Ä–∏–≤–µ—Ç . –∞ —è –æ—Ö–æ—Ç–Ω–∏–∫ , –∞ —Ç—ã ?'] ['–ü—Ä–∏–≤–µ—Ç . =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', '–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ? =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ? =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', '–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ? =>—è —Ç–æ–∂–µ .']\n"
     ]
    }
   ],
   "source": [
    "all_sent = []\n",
    "for sentence in [['–ü—Ä–∏–≤–µ—Ç .' , ' –ö–∞–∫ –¥–µ–ª–∞ ?'],['–ü—Ä–∏–≤–µ—Ç .','–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ?','–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ?']]:\n",
    "    all_sent.append( translate(model, sentence, src_vocab, src_vocab, max_len)) \n",
    "print(*all_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 1, loss 3.389, time 254.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 2, loss 3.386, time 253.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 3, loss 3.385, time 257.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 4, loss 3.384, time 252.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 5, loss 3.383, time 251.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 6, loss 3.383, time 255.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 7, loss 3.382, time 256.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 8, loss 3.382, time 258.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 9, loss 3.382, time 260.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 10, loss 3.381, time 261.4 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 11, loss 3.381, time 259.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 12, loss 3.381, time 263.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 13, loss 3.380, time 264.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 14, loss 3.380, time 262.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 15, loss 3.380, time 254.4 sec\n"
     ]
    }
   ],
   "source": [
    "lr = 0.00005\n",
    "trainer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "train(model, train_iter, lr, num_epochs, len(src_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–ü—Ä–∏–≤–µ—Ç . =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', ' –ö–∞–∫ –¥–µ–ª–∞ ? =>–ø—Ä–∏–≤–µ—Ç . —è —Ä–∞–±–æ—Ç–∞—é –≤ –æ—Ñ–∏—Å–µ .'] ['–ü—Ä–∏–≤–µ—Ç . =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', '–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ? =>–∫–∞–∫ –¥–µ–ª–∞ ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ? =>–∫–∞–∫ –¥–µ–ª–∞ ?', '–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ? =>—è —Ç–æ–∂–µ .']\n"
     ]
    }
   ],
   "source": [
    "all_sent = []\n",
    "for sentence in [['–ü—Ä–∏–≤–µ—Ç .' , ' –ö–∞–∫ –¥–µ–ª–∞ ?'],['–ü—Ä–∏–≤–µ—Ç .','–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ?','–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ?']]:\n",
    "    all_sent.append( translate(model, sentence, src_vocab, src_vocab, max_len)) \n",
    "print(*all_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 1, loss 3.379, time 261.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 2, loss 3.379, time 264.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 3, loss 3.379, time 262.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 4, loss 3.379, time 259.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 5, loss 3.379, time 250.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 6, loss 3.379, time 250.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 7, loss 3.379, time 242.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 8, loss 3.379, time 241.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 9, loss 3.379, time 240.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 10, loss 3.379, time 241.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 11, loss 3.379, time 240.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 12, loss 3.379, time 240.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 13, loss 3.379, time 240.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 14, loss 3.379, time 240.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 15, loss 3.379, time 240.3 sec\n"
     ]
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "trainer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "train(model, train_iter, lr, num_epochs, len(src_vocab), trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–ü—Ä–∏–≤–µ—Ç . =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', ' –ö–∞–∫ –¥–µ–ª–∞ ? =>–ø—Ä–∏–≤–µ—Ç . —è —Ä–∞–±–æ—Ç–∞—é –≤ –æ—Ñ–∏—Å–µ .'] ['–ü—Ä–∏–≤–µ—Ç . =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?', '–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ? =>–∫–∞–∫ –¥–µ–ª–∞ ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ? =>–∫–∞–∫ –¥–µ–ª–∞ ?', '–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ? =>—è —Ç–æ–∂–µ .']\n"
     ]
    }
   ],
   "source": [
    "all_sent = []\n",
    "for sentence in [['–ü—Ä–∏–≤–µ—Ç .' , ' –ö–∞–∫ –¥–µ–ª–∞ ?'],['–ü—Ä–∏–≤–µ—Ç .','–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ?','–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ?']]:\n",
    "    all_sent.append( translate(model, sentence, src_vocab, src_vocab, max_len)) \n",
    "print(*all_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 1, loss 3.378, time 240.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 2, loss 3.378, time 240.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 3, loss 3.378, time 240.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 4, loss 3.378, time 240.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 5, loss 3.378, time 239.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 6, loss 3.378, time 240.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 7, loss 3.378, time 240.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 8, loss 3.378, time 240.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 9, loss 3.378, time 240.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 10, loss 3.378, time 241.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 11, loss 3.378, time 240.4 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 12, loss 3.378, time 240.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 13, loss 3.378, time 239.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 14, loss 3.378, time 240.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 15, loss 3.378, time 240.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 16, loss 3.378, time 240.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 17, loss 3.378, time 240.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 18, loss 3.378, time 239.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 19, loss 3.378, time 241.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 20, loss 3.378, time 240.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 21, loss 3.378, time 240.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 22, loss 3.378, time 240.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 23, loss 3.378, time 240.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 24, loss 3.378, time 240.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 25, loss 3.378, time 240.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 26, loss 3.378, time 240.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 27, loss 3.378, time 240.4 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 28, loss 3.378, time 239.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 29, loss 3.378, time 240.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 30, loss 3.378, time 239.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 31, loss 3.378, time 240.3 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 32, loss 3.378, time 241.0 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 33, loss 3.378, time 240.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 34, loss 3.378, time 240.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 35, loss 3.378, time 240.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 36, loss 3.378, time 240.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 37, loss 3.378, time 240.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 38, loss 3.378, time 240.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 39, loss 3.378, time 240.5 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 40, loss 3.378, time 240.8 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 41, loss 3.378, time 240.4 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 42, loss 3.378, time 240.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 43, loss 3.378, time 240.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 44, loss 3.378, time 240.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 45, loss 3.378, time 240.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 46, loss 3.378, time 240.7 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 47, loss 3.378, time 239.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 48, loss 3.378, time 240.4 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 49, loss 3.378, time 240.9 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 50, loss 3.378, time 240.2 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 51, loss 3.378, time 240.4 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 52, loss 3.378, time 240.6 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 53, loss 3.378, time 240.1 sec\n",
      "batch   0   1   2   3   4   5   6   7   8   9  epoch 54, loss 3.378, time 240.0 sec\n",
      "batch   0   1   2  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-17b0d0de89fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.000005\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-8e7e74ff599e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_iter, lr, num_epochs, out_vocab_size, trainer)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_Y_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_vocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_Y_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcur_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0mnum_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_Y_vlen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 0.000005\n",
    "trainer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "train(model, train_iter, lr, 100, len(src_vocab), trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "1. –ü—Ä–∏–≤–µ—Ç . =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?\n",
      "2. –ö–∞–∫ –¥–µ–ª–∞ ? =>–ø—Ä–∏–≤–µ—Ç . –∞ —è –æ—Ö–æ—Ç–Ω–∏–∫ , –∞ —Ç—ã ?\n",
      "----------\n",
      "1. –ü—Ä–∏–≤–µ—Ç . =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?\n",
      "2. –ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ? =>–∫–∞–∫ –¥–µ–ª–∞ ?\n",
      "3. –ß—Ç–æ –¥–µ–ª–∞–µ—à—å ? =>–ø—Ä–∏–≤–µ—Ç . –∫–∞–∫ –¥–µ–ª–∞ ?\n",
      "4. –ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ? =>—è —Ç–æ–∂–µ .\n",
      "----------\n",
      "1. –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π . –ö–∞–∫ —Ç–µ–±—è –∑–æ–≤—É—Ç ? =>–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ . –∫–∞–∫ –¥–µ–ª–∞ ?\n",
      "2. –ê —Å–∫–æ–ª—å–∫–æ —Ç–µ–±–µ –ª–µ—Ç ? =>–∞ —è —Å—Ç—Ä–∏–≥—É .\n",
      "3. –Ø —Ä–∞–±–æ—Ç–∞—é —Å—Ç–∞–ª–µ–≤–∞—Ä–æ–º . –ê —Ç—ã ? =>—è –ø–µ–≤–µ—Ü .\n",
      "4. –Ø –ª—é–±–ª—é —Å–º–æ—Ç—Ä–µ—Ç—å –∫–∏–Ω–æ ? =>–ø—Ä–∏–≤–µ—Ç . –∞ —è —Ä–∞–±–æ—Ç–∞—é –≤ –∞–≤—Ç–æ—Å–µ—Ä–≤–∏—Å–µ .\n",
      "5. –ß—Ç–æ —Ç—ã —Å–µ–π—á–∞—Å –¥–µ–ª–∞–µ—à—å ? =>–ø—Ä–∏–≤–µ—Ç .\n",
      "6. –ì–¥–µ —Ç—ã —Ä–∞–±–æ—Ç–∞–µ—à—å ? =>–ø—Ä–∏–≤–µ—Ç .\n",
      "7. –ü–æ–∫–∞ . =>–ø—Ä–∏–≤–µ—Ç . –∞ —Ç—ã ?\n"
     ]
    }
   ],
   "source": [
    "all_sent = []\n",
    "for sentence in [['–ü—Ä–∏–≤–µ—Ç .' , '–ö–∞–∫ –¥–µ–ª–∞ ?'],\n",
    "                 ['–ü—Ä–∏–≤–µ—Ç .','–ö–∞–∫ —Ç—ã —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å ?', '–ß—Ç–æ –¥–µ–ª–∞–µ—à—å ?','–ì—É–ª—è—Ç—å –ø–æ–π–¥–µ—à—å ?'],\n",
    "                 ['–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π . –ö–∞–∫ —Ç–µ–±—è –∑–æ–≤—É—Ç ?','–ê —Å–∫–æ–ª—å–∫–æ —Ç–µ–±–µ –ª–µ—Ç ?','–Ø —Ä–∞–±–æ—Ç–∞—é —Å—Ç–∞–ª–µ–≤–∞—Ä–æ–º . –ê —Ç—ã ?','–Ø –ª—é–±–ª—é —Å–º–æ—Ç—Ä–µ—Ç—å –∫–∏–Ω–æ ?','–ß—Ç–æ —Ç—ã —Å–µ–π—á–∞—Å –¥–µ–ª–∞–µ—à—å ?','–ì–¥–µ —Ç—ã —Ä–∞–±–æ—Ç–∞–µ—à—å ?','–ü–æ–∫–∞ .']]:\n",
    "    all_sent.append( translate(model, sentence, src_vocab, src_vocab, max_len)) \n",
    "for i in all_sent:\n",
    "    print('----------')\n",
    "    for ind, s in enumerate(i):\n",
    "        print(f\"{ind+1}. {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞—á–µ—Å—Ç–≤–æ —Ä–µ—à–µ–Ω–∏—è —Ç–∞–∫ —Å–µ–±–µ. \n",
    "–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –Ω–∞ –¥–∞–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –ø–æ–ª—É—á–∏—Ç—å —Ä–µ—à–µ–Ω–∏–µ –ª—É—á—à–µ.\n",
    "–î–æ–ª–≥–æ –æ–±—É—á–∞–ª –º–æ–¥–µ–ª—å,–∏—Å–ø–æ–ª—å–∑—É—è —Ä–∞–∑–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã, \n",
    "–Ω–æ –ø–æ–º–æ–≥–ª–æ –Ω–µ –æ—á–µ–Ω—å. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw_9.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
